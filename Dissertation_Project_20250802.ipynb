{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinnbl/Dissertation_Project/blob/main/Dissertation_Project_20250802.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSeyIFutciOT"
      },
      "source": [
        "# Social Media and Marketing Engagement Metrics Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlK0cLs_ckKu"
      },
      "source": [
        "### Connect to Instagram API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPWC6pU2V9bY"
      },
      "source": [
        "#### Validate API Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ERdHy0Re1kq4",
        "outputId": "8c2a40b0-3a70-4c73-be01-5df18a018b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Testing Facebook API Connection...\n",
            "‚úÖ Token Validation: SUCCESS (0.219s)\n",
            "   Status Code: 200\n",
            "   Token Valid: True\n",
            "   Permissions: 8 scopes\n",
            "\n",
            "üìä API Performance Summary:\n",
            "   Token Validation: ‚úÖ SUCCESS - 218.6ms\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Your existing credentials\n",
        "user_access_token = \"EAAdMs2ZBSSwYBPPncGeEQ9VPKcgBgzuQEPWEEHw43ZA4sqzptgZCSeGZANbdEARzYphNdNItjP2LPnmJ7Vr28u8ngC8Yk3JfYEcvTSZAWNYQUxxypy2ZCGXKNG69Dl9k1ljNfre7avG8MaObVGk57BNgrvzMF2WZA5rbdl0pOZBCZBMxVmBYEw3ZBPHIvtU9wlrZBpEGWebI4efuCSAkHdqYhz7ZCpHqpY4DN5Lji9piQm06ZAchtyNN5\"\n",
        "app_id = \"2054658391689990\"\n",
        "app_secret = \"1594e932de5d0bd1a3b49979d08e7f37\"\n",
        "app_access_token = f\"{app_id}|{app_secret}\"\n",
        "\n",
        "# Track API performance\n",
        "api_performance = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'platform': 'Facebook/Meta',\n",
        "    'operations': []\n",
        "}\n",
        "\n",
        "# 1. Token Validation with Performance Tracking\n",
        "print(\"üîç Testing Facebook API Connection...\")\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    url = \"https://graph.facebook.com/debug_token\"\n",
        "    params = {\n",
        "        \"input_token\": user_access_token,\n",
        "        \"access_token\": app_access_token\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    response_time = time.time() - start_time\n",
        "\n",
        "    # Log results\n",
        "    operation = {\n",
        "        'operation': 'Token Validation',\n",
        "        'status_code': response.status_code,\n",
        "        'response_time_ms': round(response_time * 1000, 2),\n",
        "        'success': response.status_code == 200,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    api_performance['operations'].append(operation)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        token_data = response.json()\n",
        "        print(f\"‚úÖ Token Validation: SUCCESS ({response_time:.3f}s)\")\n",
        "        print(f\"   Status Code: {response.status_code}\")\n",
        "        print(f\"   Token Valid: {token_data.get('data', {}).get('is_valid', 'Unknown')}\")\n",
        "        print(f\"   Permissions: {len(token_data.get('data', {}).get('scopes', []))} scopes\")\n",
        "    else:\n",
        "        print(f\"‚ùå Token Validation: FAILED ({response_time:.3f}s)\")\n",
        "        print(f\"   Status Code: {response.status_code}\")\n",
        "        print(f\"   Error: {response.text}\")\n",
        "\n",
        "except Exception as e:\n",
        "    response_time = time.time() - start_time\n",
        "    print(f\"‚ùå Connection Error: {e}\")\n",
        "    api_performance['operations'].append({\n",
        "        'operation': 'Token Validation',\n",
        "        'status_code': 'ERROR',\n",
        "        'response_time_ms': round(response_time * 1000, 2),\n",
        "        'success': False,\n",
        "        'error': str(e)\n",
        "    })\n",
        "\n",
        "# Display Performance Summary\n",
        "print(\"\\nüìä API Performance Summary:\")\n",
        "for op in api_performance['operations']:\n",
        "    status = \"‚úÖ SUCCESS\" if op['success'] else \"‚ùå FAILED\"\n",
        "    print(f\"   {op['operation']}: {status} - {op['response_time_ms']}ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FO7l6JyWEvj"
      },
      "source": [
        "#### Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljQe80nn20Q1"
      },
      "source": [
        "#### Get only media metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AZWZc3spx_r7",
        "outputId": "abf07009-d890-4b0e-a24b-c497dd218e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fetching posts and stories...\n",
            "‚è∞ Process started at: 2025-08-02T14:41:58.023750\n",
            "üìä Starting media fetch operation...\n",
            "‚úÖ Media Fetch Page 1: 245.27ms - Status 200\n",
            "üìÑ Page 1: Retrieved 4 items\n",
            "üìä Media fetch completed: 4 items in 0.75s\n",
            "‚úÖ 4 media items found after 2024-01-01\n",
            "‚è±Ô∏è Filtering completed in 0.00s\n",
            "üîÑ Processing item 1/4: VIDEO\n",
            "‚ùå Insights for VIDEO: 169.25ms - Status 400\n",
            "üö® Error in Insights API: HTTP 400: {\"error\":{\"message\":\"(#100) The Media Insights API does not support the video_views metric for this media product type.\",\"type\":\"OAuthException\",\"code\":100,\"fbtrace_id\":\"Ar3l718E_evywPkKX6qQ7Et\"}}\n",
            "üîÑ Processing item 2/4: IMAGE\n",
            "‚úÖ Insights for IMAGE: 285.95ms - Status 200\n",
            "üîÑ Processing item 3/4: IMAGE\n",
            "‚úÖ Insights for IMAGE: 299.05ms - Status 200\n",
            "üîÑ Processing item 4/4: IMAGE\n",
            "‚úÖ Insights for IMAGE: 260.87ms - Status 200\n",
            "üìÅ Data saved to instagram_media_metrics.csv in 0.00s\n",
            "\n",
            "============================================================\n",
            "üìä PERFORMANCE SUMMARY\n",
            "============================================================\n",
            "‚è±Ô∏è Total Execution Time: 3.77 seconds\n",
            "üåê API Calls Made: 5\n",
            "‚úÖ Successful API Calls: 4\n",
            "‚ùå Failed API Calls: 1\n",
            "üìà Average API Response Time: 252.08ms\n",
            "üìà Max API Response Time: 299.05ms\n",
            "üìà Min API Response Time: 169.25ms\n",
            "üìä Items Processed: 4\n",
            "üîç Items After Filtering: 4\n",
            "‚úÖ Successful Insights Calls: 3\n",
            "‚ùå Failed Insights Calls: 1\n",
            "üìä Overall API Success Rate: 80.0%\n",
            "üìä Insights API Success Rate: 75.0%\n",
            "\n",
            "üö® Errors Encountered: 1\n",
            "   - Insights API: str\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import csv\n",
        "from datetime import datetime, timezone\n",
        "import traceback\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "ACCESS_TOKEN = user_access_token  # Replace with your token\n",
        "IG_USER_ID = '17841474204478957'              # Your IG Business Account ID\n",
        "FILTER_FROM_DATE = datetime.strptime(\"2024-01-01\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "\n",
        "# === PERFORMANCE TRACKING ===\n",
        "performance_stats = {\n",
        "    'start_time': time.time(),\n",
        "    'api_calls': {\n",
        "        'total': 0,\n",
        "        'successful': 0,\n",
        "        'failed': 0,\n",
        "        'response_times': []\n",
        "    },\n",
        "    'data_processing': {\n",
        "        'items_processed': 0,\n",
        "        'items_filtered': 0,\n",
        "        'insights_successful': 0,\n",
        "        'insights_failed': 0,\n",
        "        'total_processing_time': 0\n",
        "    },\n",
        "    'errors': []\n",
        "}\n",
        "\n",
        "def log_api_call(operation, response_time, status_code, success=True):\n",
        "    \"\"\"Log API call performance\"\"\"\n",
        "    performance_stats['api_calls']['total'] += 1\n",
        "    performance_stats['api_calls']['response_times'].append(response_time)\n",
        "\n",
        "    if success and status_code == 200:\n",
        "        performance_stats['api_calls']['successful'] += 1\n",
        "        print(f\"‚úÖ {operation}: {response_time:.2f}ms - Status {status_code}\")\n",
        "    else:\n",
        "        performance_stats['api_calls']['failed'] += 1\n",
        "        print(f\"‚ùå {operation}: {response_time:.2f}ms - Status {status_code}\")\n",
        "\n",
        "def log_error(component, error, item_id=None):\n",
        "    \"\"\"Log errors with context\"\"\"\n",
        "    error_entry = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'component': component,\n",
        "        'error_type': type(error).__name__,\n",
        "        'error_message': str(error),\n",
        "        'item_id': item_id\n",
        "    }\n",
        "    performance_stats['errors'].append(error_entry)\n",
        "    print(f\"üö® Error in {component}: {error}\")\n",
        "\n",
        "# === FETCH REGULAR MEDIA ===\n",
        "def get_all_media(ig_user_id, access_token):\n",
        "    print(\"üìä Starting media fetch operation...\")\n",
        "    fetch_start = time.time()\n",
        "\n",
        "    url = f'https://graph.facebook.com/v22.0/{ig_user_id}/media'\n",
        "    params = {\n",
        "        'fields': 'username,id,caption,media_type,timestamp,permalink,like_count,comments_count',\n",
        "        'access_token': access_token\n",
        "    }\n",
        "\n",
        "    media_items = []\n",
        "    page_count = 0\n",
        "\n",
        "    while url:\n",
        "        page_start = time.time()\n",
        "\n",
        "        try:\n",
        "            res = requests.get(url, params=params if '?' not in url else {})\n",
        "            response_time = (time.time() - page_start) * 1000\n",
        "\n",
        "            page_count += 1\n",
        "            log_api_call(f\"Media Fetch Page {page_count}\", response_time, res.status_code, res.status_code == 200)\n",
        "\n",
        "            if res.status_code != 200:\n",
        "                log_error(\"Media Fetch\", f\"HTTP {res.status_code}: {res.text}\")\n",
        "                break\n",
        "\n",
        "            data = res.json()\n",
        "            media_items.extend(data.get('data', []))\n",
        "            url = data.get('paging', {}).get('next', None)\n",
        "\n",
        "            print(f\"üìÑ Page {page_count}: Retrieved {len(data.get('data', []))} items\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            log_error(\"Media Fetch\", e)\n",
        "            break\n",
        "\n",
        "    fetch_duration = time.time() - fetch_start\n",
        "    print(f\"üìä Media fetch completed: {len(media_items)} items in {fetch_duration:.2f}s\")\n",
        "\n",
        "    return media_items\n",
        "\n",
        "# === FETCH INSIGHTS FOR MEDIA ===\n",
        "def get_insights_for_media(media_id, media_type, access_token):\n",
        "    insights_start = time.time()\n",
        "\n",
        "    url = f'https://graph.facebook.com/v22.0/{media_id}/insights'\n",
        "\n",
        "    if media_type == 'REEL':\n",
        "        metrics = 'reach,views,plays,video_views,likes,comments,saved,shares'\n",
        "    elif media_type == 'VIDEO':\n",
        "        metrics = 'reach,views,video_views,likes,comments,saved'\n",
        "    else:\n",
        "        metrics = 'reach,likes,comments,saved'\n",
        "\n",
        "    params = {\n",
        "        'metric': metrics,\n",
        "        'access_token': access_token\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, params=params)\n",
        "        response_time = (time.time() - insights_start) * 1000\n",
        "\n",
        "        log_api_call(f\"Insights for {media_type}\", response_time, res.status_code, res.status_code == 200)\n",
        "\n",
        "        metrics_data = {}\n",
        "        if res.status_code == 200:\n",
        "            performance_stats['data_processing']['insights_successful'] += 1\n",
        "            for item in res.json().get('data', []):\n",
        "                if 'values' in item and item['values']:\n",
        "                    metrics_data[item['name']] = item['values'][0].get('value', '')\n",
        "                else:\n",
        "                    metrics_data[item['name']] = ''\n",
        "        else:\n",
        "            performance_stats['data_processing']['insights_failed'] += 1\n",
        "            log_error(\"Insights API\", f\"HTTP {res.status_code}: {res.text}\", media_id)\n",
        "\n",
        "    except Exception as e:\n",
        "        performance_stats['data_processing']['insights_failed'] += 1\n",
        "        log_error(\"Insights API\", e, media_id)\n",
        "        metrics_data = {}\n",
        "\n",
        "    return metrics_data\n",
        "\n",
        "# === MAIN FUNCTION ===\n",
        "def main():\n",
        "    print(\"üîç Fetching posts and stories...\")\n",
        "    print(f\"‚è∞ Process started at: {datetime.now().isoformat()}\")\n",
        "\n",
        "    processing_start = time.time()\n",
        "\n",
        "    # Fetch all media\n",
        "    all_media = get_all_media(IG_USER_ID, ACCESS_TOKEN)\n",
        "    performance_stats['data_processing']['items_processed'] = len(all_media)\n",
        "\n",
        "    # Filter by date\n",
        "    filter_start = time.time()\n",
        "    filtered_items = []\n",
        "\n",
        "    for item in all_media:\n",
        "        try:\n",
        "            media_date = datetime.strptime(item['timestamp'], \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "            if media_date >= FILTER_FROM_DATE:\n",
        "                filtered_items.append(item)\n",
        "        except Exception as e:\n",
        "            log_error(\"Date Filtering\", e, item.get('id', 'unknown'))\n",
        "\n",
        "    filter_duration = time.time() - filter_start\n",
        "    performance_stats['data_processing']['items_filtered'] = len(filtered_items)\n",
        "\n",
        "    print(f\"‚úÖ {len(filtered_items)} media items found after {FILTER_FROM_DATE.date()}\")\n",
        "    print(f\"‚è±Ô∏è Filtering completed in {filter_duration:.2f}s\")\n",
        "\n",
        "    # Process insights for each item\n",
        "    insights_start = time.time()\n",
        "    results = []\n",
        "\n",
        "    for i, item in enumerate(filtered_items, 1):\n",
        "        print(f\"üîÑ Processing item {i}/{len(filtered_items)}: {item['media_type']}\")\n",
        "\n",
        "        media_type = item['media_type']\n",
        "        insights = get_insights_for_media(item['id'], media_type, ACCESS_TOKEN)\n",
        "\n",
        "        results.append({\n",
        "            'username': item.get('username', ''),\n",
        "            'permalink': item.get('permalink', ''),\n",
        "            'id': item['id'],\n",
        "            'caption': item.get('caption', ''),\n",
        "            'timestamp': item['timestamp'],\n",
        "            'media_type': media_type,\n",
        "            'like_count': item.get('like_count', '') if media_type != 'STORY' else '',\n",
        "            'reach': insights.get('reach', ''),\n",
        "            'video_views': insights.get('views', '') if media_type in ['REEL', 'VIDEO'] else '',\n",
        "            'plays': insights.get('plays', '') if media_type in ['REEL'] else '',\n",
        "            'Platform': 'Instagram',\n",
        "        })\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    insights_duration = time.time() - insights_start\n",
        "\n",
        "    # Save results\n",
        "    export_start = time.time()\n",
        "    if results:\n",
        "        with open('instagram_media_metrics.csv', 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
        "            writer.writeheader()\n",
        "            writer.writerows(results)\n",
        "        export_duration = time.time() - export_start\n",
        "        print(f\"üìÅ Data saved to instagram_media_metrics.csv in {export_duration:.2f}s\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No media to save.\")\n",
        "\n",
        "    # Calculate final stats\n",
        "    total_duration = time.time() - processing_start\n",
        "    performance_stats['data_processing']['total_processing_time'] = total_duration\n",
        "\n",
        "    # === PERFORMANCE SUMMARY ===\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"‚è±Ô∏è Total Execution Time: {total_duration:.2f} seconds\")\n",
        "    print(f\"üåê API Calls Made: {performance_stats['api_calls']['total']}\")\n",
        "    print(f\"‚úÖ Successful API Calls: {performance_stats['api_calls']['successful']}\")\n",
        "    print(f\"‚ùå Failed API Calls: {performance_stats['api_calls']['failed']}\")\n",
        "\n",
        "    if performance_stats['api_calls']['response_times']:\n",
        "        avg_response = sum(performance_stats['api_calls']['response_times']) / len(performance_stats['api_calls']['response_times'])\n",
        "        max_response = max(performance_stats['api_calls']['response_times'])\n",
        "        min_response = min(performance_stats['api_calls']['response_times'])\n",
        "        print(f\"üìà Average API Response Time: {avg_response:.2f}ms\")\n",
        "        print(f\"üìà Max API Response Time: {max_response:.2f}ms\")\n",
        "        print(f\"üìà Min API Response Time: {min_response:.2f}ms\")\n",
        "\n",
        "    print(f\"üìä Items Processed: {performance_stats['data_processing']['items_processed']}\")\n",
        "    print(f\"üîç Items After Filtering: {performance_stats['data_processing']['items_filtered']}\")\n",
        "    print(f\"‚úÖ Successful Insights Calls: {performance_stats['data_processing']['insights_successful']}\")\n",
        "    print(f\"‚ùå Failed Insights Calls: {performance_stats['data_processing']['insights_failed']}\")\n",
        "\n",
        "    # Success rates\n",
        "    if performance_stats['api_calls']['total'] > 0:\n",
        "        api_success_rate = (performance_stats['api_calls']['successful'] / performance_stats['api_calls']['total']) * 100\n",
        "        print(f\"üìä Overall API Success Rate: {api_success_rate:.1f}%\")\n",
        "\n",
        "    insights_total = performance_stats['data_processing']['insights_successful'] + performance_stats['data_processing']['insights_failed']\n",
        "    if insights_total > 0:\n",
        "        insights_success_rate = (performance_stats['data_processing']['insights_successful'] / insights_total) * 100\n",
        "        print(f\"üìä Insights API Success Rate: {insights_success_rate:.1f}%\")\n",
        "\n",
        "    # Error summary\n",
        "    if performance_stats['errors']:\n",
        "        print(f\"\\nüö® Errors Encountered: {len(performance_stats['errors'])}\")\n",
        "        for error in performance_stats['errors']:\n",
        "            print(f\"   - {error['component']}: {error['error_type']}\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ No errors encountered!\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Return stats for further analysis\n",
        "    return performance_stats, results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    stats, data = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "G_i17ox-DT8O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "9Vt-iPXy1zfc",
        "outputId": "ad168a83-3ee7-4d28-cbb2-447ca5aa02f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        username                                    permalink  \\\n",
              "0  mnblanalytics  https://www.instagram.com/reel/DKWmrCONQqs/   \n",
              "1  mnblanalytics     https://www.instagram.com/p/DJ4VPz6tPPb/   \n",
              "2  mnblanalytics     https://www.instagram.com/p/DJb6pZWtXKt/   \n",
              "3  mnblanalytics     https://www.instagram.com/p/DJb6PloNTog/   \n",
              "\n",
              "                  id       caption                 timestamp media_type  \\\n",
              "0  18080236366793735      Testreel  2025-06-01T09:30:07+0000      VIDEO   \n",
              "1  18080278336761002  #Iniciative1  2025-05-20T15:20:22+0000      IMAGE   \n",
              "2  17904426585155969        Test 2  2025-05-09T14:29:12+0000      IMAGE   \n",
              "3  18079149412810358        Test 1  2025-05-09T14:25:41+0000      IMAGE   \n",
              "\n",
              "   like_count  reach  video_views  plays   Platform  \n",
              "0           5    NaN          NaN    NaN  Instagram  \n",
              "1           5   32.0          NaN    NaN  Instagram  \n",
              "2           6   40.0          NaN    NaN  Instagram  \n",
              "3           7   38.0          NaN    NaN  Instagram  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d042998-5a3d-4c9d-a0fe-4b47b1fe83e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>permalink</th>\n",
              "      <th>id</th>\n",
              "      <th>caption</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>media_type</th>\n",
              "      <th>like_count</th>\n",
              "      <th>reach</th>\n",
              "      <th>video_views</th>\n",
              "      <th>plays</th>\n",
              "      <th>Platform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/reel/DKWmrCONQqs/</td>\n",
              "      <td>18080236366793735</td>\n",
              "      <td>Testreel</td>\n",
              "      <td>2025-06-01T09:30:07+0000</td>\n",
              "      <td>VIDEO</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/p/DJ4VPz6tPPb/</td>\n",
              "      <td>18080278336761002</td>\n",
              "      <td>#Iniciative1</td>\n",
              "      <td>2025-05-20T15:20:22+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>5</td>\n",
              "      <td>32.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/p/DJb6pZWtXKt/</td>\n",
              "      <td>17904426585155969</td>\n",
              "      <td>Test 2</td>\n",
              "      <td>2025-05-09T14:29:12+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>6</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/p/DJb6PloNTog/</td>\n",
              "      <td>18079149412810358</td>\n",
              "      <td>Test 1</td>\n",
              "      <td>2025-05-09T14:25:41+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>7</td>\n",
              "      <td>38.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d042998-5a3d-4c9d-a0fe-4b47b1fe83e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d042998-5a3d-4c9d-a0fe-4b47b1fe83e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d042998-5a3d-4c9d-a0fe-4b47b1fe83e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2fe8aeb-d2c3-4f86-bf31-76ff295fc82f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2fe8aeb-d2c3-4f86-bf31-76ff295fc82f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2fe8aeb-d2c3-4f86-bf31-76ff295fc82f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_78d19b35-40d4-42fc-98dd-841731d16897\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_78d19b35-40d4-42fc-98dd-841731d16897 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_2",
              "summary": "{\n  \"name\": \"df_2\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mnblanalytics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"permalink\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"https://www.instagram.com/p/DJ4VPz6tPPb/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87732283142785,\n        \"min\": 17904426585155969,\n        \"max\": 18080278336761002,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          18080278336761002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"#Iniciative1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-05-20T15:20:22+0000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"media_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"IMAGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"like_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.163331998932266,\n        \"min\": 32.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Platform\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_2= pd.read_csv('instagram_media_metrics.csv')\n",
        "df_2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDdqYxRFuvlL"
      },
      "source": [
        "### Get only Stories Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eGZiuC8ouyIu",
        "outputId": "e177d1b9-2eb6-4b27-ea9b-abbfa4f8695b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fetching Instagram Stories...\n",
            "‚è∞ Stories process started at: 2025-08-02T14:42:16.866177\n",
            "üìä Starting stories fetch operation...\n",
            "‚úÖ Stories Fetch: 386.31ms - Status 200 - 2 items\n",
            "üìä Found 2 active stories\n",
            "\n",
            "üîÑ Processing story 1/2\n",
            "   Story ID: 17929674428964127\n",
            "   Type: IMAGE\n",
            "   Timestamp: 2025-08-02T13:54:17+0000\n",
            "   Caption: TEST 3\n",
            "‚úÖ Story Insights: 426.05ms - Status 200 - 4 items\n",
            "   Reach: 11\n",
            "   Replies: 0\n",
            "   Total_interactions: 0\n",
            "   Views: 12\n",
            "--------------------------------------------------\n",
            "\n",
            "üîÑ Processing story 2/2\n",
            "   Story ID: 18016504853574187\n",
            "   Type: IMAGE\n",
            "   Timestamp: 2025-08-02T13:53:44+0000\n",
            "   Caption: Test\n",
            "‚úÖ Story Insights: 468.59ms - Status 200 - 4 items\n",
            "   Reach: 12\n",
            "   Replies: 0\n",
            "   Total_interactions: 0\n",
            "   Views: 13\n",
            "--------------------------------------------------\n",
            "üìÅ Stories data saved to instagram_stories_detailed.csv in 0.00s\n",
            "\n",
            "============================================================\n",
            "üìä INSTAGRAM STORIES PERFORMANCE SUMMARY\n",
            "============================================================\n",
            "‚è±Ô∏è Total Execution Time: 2.29 seconds\n",
            "üåê Total API Calls: 3\n",
            "‚úÖ Successful API Calls: 3\n",
            "‚ùå Failed API Calls: 0\n",
            "üìà Average API Response Time: 426.98ms\n",
            "üìà Max API Response Time: 468.59ms\n",
            "üìà Min API Response Time: 386.31ms\n",
            "üì± Stories Found: 2\n",
            "üîÑ Stories Processed: 2\n",
            "‚úÖ Insights Retrieved: 2\n",
            "‚ùå Insights Failed: 0\n",
            "‚ÑπÔ∏è Insufficient Data Cases: 0\n",
            "üìä Overall API Success Rate: 100.0%\n",
            "üìä Insights Success Rate: 100.0%\n",
            "\n",
            "üìä DATA QUALITY METRICS:\n",
            "   Complete Stories (with insights): 2\n",
            "   Stories with Insights: 2\n",
            "   Stories without Insights: 0\n",
            "   Data Completeness Rate: 100.0%\n",
            "\n",
            "‚úÖ No errors encountered!\n",
            "\n",
            "üí° PERFORMANCE INSIGHTS:\n",
            "   - API response times averaging 427ms indicate good performance\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import traceback\n",
        "\n",
        "ACCESS_TOKEN = user_access_token\n",
        "IG_USER_ID = '17841474204478957'\n",
        "\n",
        "# === PERFORMANCE TRACKING ===\n",
        "stories_performance_stats = {\n",
        "    'start_time': time.time(),\n",
        "    'api_calls': {\n",
        "        'total': 0,\n",
        "        'successful': 0,\n",
        "        'failed': 0,\n",
        "        'response_times': []\n",
        "    },\n",
        "    'stories_processing': {\n",
        "        'stories_found': 0,\n",
        "        'stories_processed': 0,\n",
        "        'insights_successful': 0,\n",
        "        'insights_failed': 0,\n",
        "        'insights_insufficient_data': 0,\n",
        "        'total_processing_time': 0\n",
        "    },\n",
        "    'errors': [],\n",
        "    'data_quality': {\n",
        "        'complete_stories': 0,\n",
        "        'stories_with_insights': 0,\n",
        "        'stories_without_insights': 0\n",
        "    }\n",
        "}\n",
        "\n",
        "def log_stories_api_call(operation, response_time, status_code, success=True, data_count=0):\n",
        "    \"\"\"Log API call performance for stories\"\"\"\n",
        "    stories_performance_stats['api_calls']['total'] += 1\n",
        "    stories_performance_stats['api_calls']['response_times'].append(response_time)\n",
        "\n",
        "    if success and status_code == 200:\n",
        "        stories_performance_stats['api_calls']['successful'] += 1\n",
        "        print(f\"‚úÖ {operation}: {response_time:.2f}ms - Status {status_code} - {data_count} items\")\n",
        "    else:\n",
        "        stories_performance_stats['api_calls']['failed'] += 1\n",
        "        print(f\"‚ùå {operation}: {response_time:.2f}ms - Status {status_code}\")\n",
        "\n",
        "def log_stories_error(component, error, story_id=None):\n",
        "    \"\"\"Log errors with context for stories\"\"\"\n",
        "    error_entry = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'component': component,\n",
        "        'error_type': type(error).__name__,\n",
        "        'error_message': str(error),\n",
        "        'story_id': story_id\n",
        "    }\n",
        "    stories_performance_stats['errors'].append(error_entry)\n",
        "    print(f\"üö® Stories Error in {component}: {error}\")\n",
        "\n",
        "def get_stories(ig_user_id, access_token):\n",
        "    print(\"üìä Starting stories fetch operation...\")\n",
        "    fetch_start = time.time()\n",
        "\n",
        "    url = f'https://graph.facebook.com/v19.0/{ig_user_id}/stories'\n",
        "    params = {\n",
        "        'fields': 'username,id,media_type,media_url,timestamp,permalink,caption',\n",
        "        'access_token': access_token\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, params=params)\n",
        "        response_time = (time.time() - fetch_start) * 1000\n",
        "\n",
        "        stories_data = []\n",
        "        if res.status_code == 200:\n",
        "            stories_data = res.json().get('data', [])\n",
        "            stories_performance_stats['stories_processing']['stories_found'] = len(stories_data)\n",
        "            log_stories_api_call(\"Stories Fetch\", response_time, res.status_code, True, len(stories_data))\n",
        "        else:\n",
        "            log_stories_api_call(\"Stories Fetch\", response_time, res.status_code, False)\n",
        "            log_stories_error(\"Stories Fetch\", f\"HTTP {res.status_code}: {res.text}\")\n",
        "\n",
        "        return stories_data\n",
        "\n",
        "    except Exception as e:\n",
        "        response_time = (time.time() - fetch_start) * 1000\n",
        "        log_stories_error(\"Stories Fetch\", e)\n",
        "        return []\n",
        "\n",
        "def get_story_insights(media_id, access_token):\n",
        "    insights_start = time.time()\n",
        "\n",
        "    # Allowed metrics for story insights in latest API versions\n",
        "    metrics = \"reach,replies,total_interactions,views\"\n",
        "    url = f'https://graph.facebook.com/v22.0/{media_id}/insights'\n",
        "    params = {\n",
        "        'metric': metrics,\n",
        "        'access_token': access_token\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, params=params)\n",
        "        response_time = (time.time() - insights_start) * 1000\n",
        "\n",
        "        insights = {}\n",
        "        if res.status_code == 200:\n",
        "            stories_performance_stats['stories_processing']['insights_successful'] += 1\n",
        "            stories_performance_stats['data_quality']['stories_with_insights'] += 1\n",
        "\n",
        "            data = res.json().get('data', [])\n",
        "            for item in data:\n",
        "                if 'values' in item and item['values']:\n",
        "                    insights[item['name']] = item['values'][0]['value']\n",
        "                else:\n",
        "                    insights[item['name']] = 0\n",
        "\n",
        "            log_stories_api_call(f\"Story Insights\", response_time, res.status_code, True, len(insights))\n",
        "\n",
        "        else:\n",
        "            stories_performance_stats['stories_processing']['insights_failed'] += 1\n",
        "            stories_performance_stats['data_quality']['stories_without_insights'] += 1\n",
        "\n",
        "            # Check if it's insufficient data error\n",
        "            if \"Not enough viewers\" in res.text or \"insufficient data\" in res.text.lower():\n",
        "                stories_performance_stats['stories_processing']['insights_insufficient_data'] += 1\n",
        "                print(f\"‚ÑπÔ∏è Insufficient data for story {media_id} insights (normal for low-view stories)\")\n",
        "            else:\n",
        "                log_stories_error(\"Story Insights\", f\"HTTP {res.status_code}: {res.text}\", media_id)\n",
        "\n",
        "            log_stories_api_call(f\"Story Insights\", response_time, res.status_code, False)\n",
        "\n",
        "    except Exception as e:\n",
        "        stories_performance_stats['stories_processing']['insights_failed'] += 1\n",
        "        stories_performance_stats['data_quality']['stories_without_insights'] += 1\n",
        "        log_stories_error(\"Story Insights\", e, media_id)\n",
        "        insights = {}\n",
        "\n",
        "    return insights\n",
        "\n",
        "def main():\n",
        "    print(\"üîç Fetching Instagram Stories...\")\n",
        "    print(f\"‚è∞ Stories process started at: {datetime.now().isoformat()}\")\n",
        "\n",
        "    processing_start = time.time()\n",
        "\n",
        "    # Fetch stories\n",
        "    stories = get_stories(IG_USER_ID, ACCESS_TOKEN)\n",
        "\n",
        "    if not stories:\n",
        "        print(\"‚ö†Ô∏è No stories found.\")\n",
        "        # Still generate performance report\n",
        "        generate_stories_performance_report(processing_start, [])\n",
        "        return []\n",
        "\n",
        "    print(f\"üìä Found {len(stories)} active stories\")\n",
        "\n",
        "    # Process each story\n",
        "    story_data = []\n",
        "    stories_performance_stats['stories_processing']['stories_processed'] = len(stories)\n",
        "\n",
        "    for i, story in enumerate(stories, 1):\n",
        "        print(f\"\\nüîÑ Processing story {i}/{len(stories)}\")\n",
        "        print(f\"   Story ID: {story.get('id')}\")\n",
        "        print(f\"   Type: {story.get('media_type')}\")\n",
        "        print(f\"   Timestamp: {story.get('timestamp')}\")\n",
        "        print(f\"   Caption: {story.get('caption', 'No caption')}\")\n",
        "\n",
        "        story_processing_start = time.time()\n",
        "        insights = get_story_insights(story['id'], ACCESS_TOKEN)\n",
        "        story_processing_time = time.time() - story_processing_start\n",
        "\n",
        "        # Build story data record\n",
        "        story_record = {\n",
        "            'username': story.get('username', ''),\n",
        "            'id': story.get('id'),\n",
        "            'media_type': story.get('media_type'),\n",
        "            'timestamp': story.get('timestamp'),\n",
        "            'permalink': story.get('permalink'),\n",
        "            'caption': story.get('caption', ''),\n",
        "            'reach': insights.get('reach', 0),\n",
        "            'replies': insights.get('replies', 0),\n",
        "            'total_interactions': insights.get('total_interactions', 0),\n",
        "            'views': insights.get('views', 0),\n",
        "            'Platform': 'Instagram',\n",
        "            'processing_time_ms': round(story_processing_time * 1000, 2)\n",
        "        }\n",
        "\n",
        "        story_data.append(story_record)\n",
        "\n",
        "        # Check data completeness\n",
        "        if any(insights.values()):\n",
        "            stories_performance_stats['data_quality']['complete_stories'] += 1\n",
        "\n",
        "        # Display insights\n",
        "        if insights:\n",
        "            for k, v in insights.items():\n",
        "                print(f\"   {k.capitalize()}: {v}\")\n",
        "        else:\n",
        "            print(\"   ‚ÑπÔ∏è No insights available (insufficient data)\")\n",
        "\n",
        "        print('-' * 50)\n",
        "        time.sleep(0.5)  # Be kind to the API rate limits\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_stories = pd.DataFrame(story_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    export_start = time.time()\n",
        "    try:\n",
        "        df_stories.to_csv('instagram_stories_detailed.csv', index=False)\n",
        "        export_duration = time.time() - export_start\n",
        "        print(f\"üìÅ Stories data saved to instagram_stories_detailed.csv in {export_duration:.2f}s\")\n",
        "    except Exception as e:\n",
        "        log_stories_error(\"CSV Export\", e)\n",
        "\n",
        "    # Generate performance report\n",
        "    generate_stories_performance_report(processing_start, story_data)\n",
        "\n",
        "    return story_data\n",
        "\n",
        "def generate_stories_performance_report(processing_start, story_data):\n",
        "    \"\"\"Generate comprehensive performance report\"\"\"\n",
        "    total_duration = time.time() - processing_start\n",
        "    stories_performance_stats['stories_processing']['total_processing_time'] = total_duration\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä INSTAGRAM STORIES PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Timing metrics\n",
        "    print(f\"‚è±Ô∏è Total Execution Time: {total_duration:.2f} seconds\")\n",
        "\n",
        "    # API performance\n",
        "    print(f\"üåê Total API Calls: {stories_performance_stats['api_calls']['total']}\")\n",
        "    print(f\"‚úÖ Successful API Calls: {stories_performance_stats['api_calls']['successful']}\")\n",
        "    print(f\"‚ùå Failed API Calls: {stories_performance_stats['api_calls']['failed']}\")\n",
        "\n",
        "    if stories_performance_stats['api_calls']['response_times']:\n",
        "        response_times = stories_performance_stats['api_calls']['response_times']\n",
        "        avg_response = sum(response_times) / len(response_times)\n",
        "        max_response = max(response_times)\n",
        "        min_response = min(response_times)\n",
        "        print(f\"üìà Average API Response Time: {avg_response:.2f}ms\")\n",
        "        print(f\"üìà Max API Response Time: {max_response:.2f}ms\")\n",
        "        print(f\"üìà Min API Response Time: {min_response:.2f}ms\")\n",
        "\n",
        "    # Stories processing metrics\n",
        "    print(f\"üì± Stories Found: {stories_performance_stats['stories_processing']['stories_found']}\")\n",
        "    print(f\"üîÑ Stories Processed: {stories_performance_stats['stories_processing']['stories_processed']}\")\n",
        "    print(f\"‚úÖ Insights Retrieved: {stories_performance_stats['stories_processing']['insights_successful']}\")\n",
        "    print(f\"‚ùå Insights Failed: {stories_performance_stats['stories_processing']['insights_failed']}\")\n",
        "    print(f\"‚ÑπÔ∏è Insufficient Data Cases: {stories_performance_stats['stories_processing']['insights_insufficient_data']}\")\n",
        "\n",
        "    # Success rates\n",
        "    if stories_performance_stats['api_calls']['total'] > 0:\n",
        "        api_success_rate = (stories_performance_stats['api_calls']['successful'] / stories_performance_stats['api_calls']['total']) * 100\n",
        "        print(f\"üìä Overall API Success Rate: {api_success_rate:.1f}%\")\n",
        "\n",
        "    insights_total = stories_performance_stats['stories_processing']['insights_successful'] + stories_performance_stats['stories_processing']['insights_failed']\n",
        "    if insights_total > 0:\n",
        "        insights_success_rate = (stories_performance_stats['stories_processing']['insights_successful'] / insights_total) * 100\n",
        "        print(f\"üìä Insights Success Rate: {insights_success_rate:.1f}%\")\n",
        "\n",
        "    # Data quality metrics\n",
        "    print(f\"\\nüìä DATA QUALITY METRICS:\")\n",
        "    print(f\"   Complete Stories (with insights): {stories_performance_stats['data_quality']['complete_stories']}\")\n",
        "    print(f\"   Stories with Insights: {stories_performance_stats['data_quality']['stories_with_insights']}\")\n",
        "    print(f\"   Stories without Insights: {stories_performance_stats['data_quality']['stories_without_insights']}\")\n",
        "\n",
        "    if story_data:\n",
        "        data_completeness = (stories_performance_stats['data_quality']['complete_stories'] / len(story_data)) * 100\n",
        "        print(f\"   Data Completeness Rate: {data_completeness:.1f}%\")\n",
        "\n",
        "    # Error summary\n",
        "    if stories_performance_stats['errors']:\n",
        "        print(f\"\\nüö® Errors Encountered: {len(stories_performance_stats['errors'])}\")\n",
        "        error_types = {}\n",
        "        for error in stories_performance_stats['errors']:\n",
        "            error_type = f\"{error['component']}: {error['error_type']}\"\n",
        "            error_types[error_type] = error_types.get(error_type, 0) + 1\n",
        "\n",
        "        for error_type, count in error_types.items():\n",
        "            print(f\"   - {error_type}: {count} occurrence(s)\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ No errors encountered!\")\n",
        "\n",
        "    # Performance insights\n",
        "    print(f\"\\nüí° PERFORMANCE INSIGHTS:\")\n",
        "    if stories_performance_stats['stories_processing']['insights_insufficient_data'] > 0:\n",
        "        print(f\"   - {stories_performance_stats['stories_processing']['insights_insufficient_data']} stories had insufficient data for insights (normal)\")\n",
        "\n",
        "    if stories_performance_stats['api_calls']['response_times']:\n",
        "        avg_time = sum(stories_performance_stats['api_calls']['response_times']) / len(stories_performance_stats['api_calls']['response_times'])\n",
        "        if avg_time > 1000:\n",
        "            print(f\"   - API response times averaging {avg_time:.0f}ms suggest potential network/server delays\")\n",
        "        else:\n",
        "            print(f\"   - API response times averaging {avg_time:.0f}ms indicate good performance\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return stories_performance_stats\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    story_results = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j1jZuiYTKRZP",
        "outputId": "956f0016-f8a9-4b6b-d198-71603e98285e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        username                 id media_type                 timestamp  \\\n",
            "0  mnblanalytics  17929674428964127      IMAGE  2025-08-02T13:54:17+0000   \n",
            "1  mnblanalytics  18016504853574187      IMAGE  2025-08-02T13:53:44+0000   \n",
            "\n",
            "                                           permalink caption  reach  replies  \\\n",
            "0  https://instagram.com/stories/mnblanalytics/36...  TEST 3     11        0   \n",
            "1  https://instagram.com/stories/mnblanalytics/36...    Test     12        0   \n",
            "\n",
            "   total_interactions  views   Platform  \n",
            "0                   0     12  Instagram  \n",
            "1                   0     13  Instagram  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "ACCESS_TOKEN = user_access_token\n",
        "IG_USER_ID = '17841474204478957'\n",
        "\n",
        "def get_stories(ig_user_id, access_token):\n",
        "    url = f'https://graph.facebook.com/v19.0/{ig_user_id}/stories'\n",
        "    params = {\n",
        "        'fields': 'username,id,media_type,media_url,timestamp,permalink,caption',\n",
        "        'access_token': access_token\n",
        "    }\n",
        "    res = requests.get(url, params=params)\n",
        "    if res.status_code == 200:\n",
        "        return res.json().get('data', [])\n",
        "    else:\n",
        "        print(f\"Error fetching stories: {res.status_code} {res.text}\")\n",
        "        return []\n",
        "\n",
        "def get_story_insights(media_id, access_token):\n",
        "    metrics = \"reach,replies,total_interactions,views\"\n",
        "    url = f'https://graph.facebook.com/v22.0/{media_id}/insights'\n",
        "    params = {\n",
        "        'metric': metrics,\n",
        "        'access_token': access_token\n",
        "    }\n",
        "    res = requests.get(url, params=params)\n",
        "    insights = {}\n",
        "    if res.status_code == 200:\n",
        "        for item in res.json().get('data', []):\n",
        "            insights[item['name']] = item['values'][0]['value']\n",
        "    else:\n",
        "        print(f\"Error getting insights for story {media_id}: {res.status_code} {res.text}\")\n",
        "    return insights\n",
        "\n",
        "def main():\n",
        "    stories = get_stories(IG_USER_ID, ACCESS_TOKEN)\n",
        "    if not stories:\n",
        "        print(\"No stories found.\")\n",
        "        return\n",
        "\n",
        "    story_data = []\n",
        "\n",
        "    for story in stories:\n",
        "        insights = get_story_insights(story['id'], ACCESS_TOKEN)\n",
        "        story_row = {\n",
        "           'username': story.get('username'),\n",
        "            'id': story.get('id'),\n",
        "            'media_type': story.get('media_type'),\n",
        "            #'media_url': story.get('media_url'),\n",
        "            'timestamp': story.get('timestamp'),\n",
        "            'permalink': story.get('permalink'),\n",
        "            'caption': story.get('caption', ''),\n",
        "            'reach': insights.get('reach', 0),\n",
        "            'replies': insights.get('replies', 0),\n",
        "            'total_interactions': insights.get('total_interactions', 0),\n",
        "            'views': insights.get('views', 0),\n",
        "            'Platform':'Instagram',\n",
        "        }\n",
        "        story_data.append(story_row)\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    df_stories = pd.DataFrame(story_data)\n",
        "    print(df_stories)\n",
        "\n",
        "    # Optional: Save to CSV or Excel\n",
        "    df_stories.to_csv('instagram_stories.csv', index=False)\n",
        "\n",
        "    return df_stories\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "sEw5eSd_LveX",
        "outputId": "7d2891a5-519d-4634-c753-88eba204a27a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        username                 id media_type                 timestamp  \\\n",
              "0  mnblanalytics  17929674428964127      IMAGE  2025-08-02T13:54:17+0000   \n",
              "1  mnblanalytics  18016504853574187      IMAGE  2025-08-02T13:53:44+0000   \n",
              "\n",
              "                                           permalink caption  reach  replies  \\\n",
              "0  https://instagram.com/stories/mnblanalytics/36...  TEST 3     11        0   \n",
              "1  https://instagram.com/stories/mnblanalytics/36...    Test     12        0   \n",
              "\n",
              "   total_interactions  views   Platform  \n",
              "0                   0     12  Instagram  \n",
              "1                   0     13  Instagram  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2464858-d559-4270-b19b-0b3be0935bcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>media_type</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>permalink</th>\n",
              "      <th>caption</th>\n",
              "      <th>reach</th>\n",
              "      <th>replies</th>\n",
              "      <th>total_interactions</th>\n",
              "      <th>views</th>\n",
              "      <th>Platform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>17929674428964127</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>2025-08-02T13:54:17+0000</td>\n",
              "      <td>https://instagram.com/stories/mnblanalytics/36...</td>\n",
              "      <td>TEST 3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>Instagram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>18016504853574187</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>2025-08-02T13:53:44+0000</td>\n",
              "      <td>https://instagram.com/stories/mnblanalytics/36...</td>\n",
              "      <td>Test</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>Instagram</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2464858-d559-4270-b19b-0b3be0935bcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2464858-d559-4270-b19b-0b3be0935bcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2464858-d559-4270-b19b-0b3be0935bcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89118e7d-0499-4b4c-af66-476e6402defa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89118e7d-0499-4b4c-af66-476e6402defa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89118e7d-0499-4b4c-af66-476e6402defa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_07915f10-30ee-4c9c-a2dc-e5e739ea3e77\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_07915f10-30ee-4c9c-a2dc-e5e739ea3e77 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_3",
              "summary": "{\n  \"name\": \"df_3\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mnblanalytics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61398382055080,\n        \"min\": 17929674428964127,\n        \"max\": 18016504853574187,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          18016504853574187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"media_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"IMAGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2025-08-02T13:53:44+0000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"permalink\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"https://instagram.com/stories/mnblanalytics/3690339972792276812\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 11,\n        \"max\": 12,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"replies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_interactions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 12,\n        \"max\": 13,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Platform\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Instagram\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "df_3= pd.read_csv('instagram_stories.csv')\n",
        "df_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOVCbbG3fu-"
      },
      "source": [
        "### Concatenate Ig Media & Ig Stories Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7AB3Kol625x1",
        "outputId": "3cb6e4db-afb8-4e74-f105-1d170135ee9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting Instagram Data Concatenation Process\n",
            "‚è∞ Process started at: 2025-08-02T14:42:46.929122\n",
            "============================================================\n",
            "\n",
            "üìÇ STEP 1: Loading CSV Files\n",
            "‚úÖ Media Load: instagram_media_metrics.csv loaded in 0.003s\n",
            "‚úÖ Stories Load: instagram_stories.csv loaded in 0.001s\n",
            "\n",
            "üìä STEP 2: Analyzing Source Data\n",
            "üìä Media DataFrame Analysis:\n",
            "   Rows: 4\n",
            "   Columns: 11\n",
            "   Memory Usage: 0.00 MB\n",
            "   Null Values: 9\n",
            "   Duplicate Rows: 0\n",
            "   Columns: ['username', 'permalink', 'id', 'caption', 'timestamp', 'media_type', 'like_count', 'reach', 'video_views', 'plays', 'Platform']\n",
            "üìä Stories DataFrame Analysis:\n",
            "   Rows: 2\n",
            "   Columns: 11\n",
            "   Memory Usage: 0.00 MB\n",
            "   Null Values: 0\n",
            "   Duplicate Rows: 0\n",
            "   Columns: ['username', 'id', 'media_type', 'timestamp', 'permalink', 'caption', 'reach', 'replies', 'total_interactions', 'views', 'Platform']\n",
            "\n",
            "üîç Column Analysis:\n",
            "   Common columns: 8 - ['username', 'reach', 'timestamp', 'caption', 'permalink', 'Platform', 'id', 'media_type']\n",
            "   Media-only columns: 3 - ['video_views', 'plays', 'like_count']\n",
            "   Stories-only columns: 3 - ['replies', 'views', 'total_interactions']\n",
            "\n",
            "üè∑Ô∏è STEP 3: Adding Category Identifiers\n",
            "‚úÖ Category columns added in 0.0004s\n",
            "\n",
            "üîó STEP 4: Concatenating DataFrames\n",
            "‚úÖ Concatenation completed in 0.0014s\n",
            "\n",
            "üìà STEP 5: Analyzing Combined Dataset\n",
            "üìä Combined DataFrame Analysis:\n",
            "   Rows: 6\n",
            "   Columns: 15\n",
            "   Memory Usage: 0.00 MB\n",
            "   Null Values: 27\n",
            "   Duplicate Rows: 0\n",
            "   Columns: ['username', 'permalink', 'id', 'caption', 'timestamp', 'media_type', 'like_count', 'reach', 'video_views', 'plays', 'Platform', 'media_category', 'replies', 'total_interactions', 'views']\n",
            "\n",
            "üìã Data Completeness by Column:\n",
            "   username: 100.0%\n",
            "   permalink: 100.0%\n",
            "   id: 100.0%\n",
            "   caption: 100.0%\n",
            "   timestamp: 100.0%\n",
            "   media_type: 100.0%\n",
            "   Platform: 100.0%\n",
            "   media_category: 100.0%\n",
            "   reach: 83.3%\n",
            "   like_count: 66.7%\n",
            "   replies: 33.3%\n",
            "   total_interactions: 33.3%\n",
            "   views: 33.3%\n",
            "   video_views: 0.0%\n",
            "   plays: 0.0%\n",
            "\n",
            "üìÑ STEP 6: Sample Data Preview\n",
            "\n",
            "First 5 rows of combined dataframe:\n",
            "        username                                          permalink  \\\n",
            "0  mnblanalytics        https://www.instagram.com/reel/DKWmrCONQqs/   \n",
            "1  mnblanalytics           https://www.instagram.com/p/DJ4VPz6tPPb/   \n",
            "2  mnblanalytics           https://www.instagram.com/p/DJb6pZWtXKt/   \n",
            "3  mnblanalytics           https://www.instagram.com/p/DJb6PloNTog/   \n",
            "4  mnblanalytics  https://instagram.com/stories/mnblanalytics/36...   \n",
            "\n",
            "                  id       caption                 timestamp media_type  \\\n",
            "0  18080236366793735      Testreel  2025-06-01T09:30:07+0000      VIDEO   \n",
            "1  18080278336761002  #Iniciative1  2025-05-20T15:20:22+0000      IMAGE   \n",
            "2  17904426585155969        Test 2  2025-05-09T14:29:12+0000      IMAGE   \n",
            "3  18079149412810358        Test 1  2025-05-09T14:25:41+0000      IMAGE   \n",
            "4  17929674428964127        TEST 3  2025-08-02T13:54:17+0000      IMAGE   \n",
            "\n",
            "   like_count  reach  video_views  plays   Platform media_category  replies  \\\n",
            "0         5.0    NaN          NaN    NaN  Instagram          media      NaN   \n",
            "1         5.0   32.0          NaN    NaN  Instagram          media      NaN   \n",
            "2         6.0   40.0          NaN    NaN  Instagram          media      NaN   \n",
            "3         7.0   38.0          NaN    NaN  Instagram          media      NaN   \n",
            "4         NaN   11.0          NaN    NaN  Instagram          story      0.0   \n",
            "\n",
            "   total_interactions  views  \n",
            "0                 NaN    NaN  \n",
            "1                 NaN    NaN  \n",
            "2                 NaN    NaN  \n",
            "3                 NaN    NaN  \n",
            "4                 0.0   12.0  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   username            6 non-null      object \n",
            " 1   permalink           6 non-null      object \n",
            " 2   id                  6 non-null      int64  \n",
            " 3   caption             6 non-null      object \n",
            " 4   timestamp           6 non-null      object \n",
            " 5   media_type          6 non-null      object \n",
            " 6   like_count          4 non-null      float64\n",
            " 7   reach               5 non-null      float64\n",
            " 8   video_views         0 non-null      float64\n",
            " 9   plays               0 non-null      float64\n",
            " 10  Platform            6 non-null      object \n",
            " 11  media_category      6 non-null      object \n",
            " 12  replies             2 non-null      float64\n",
            " 13  total_interactions  2 non-null      float64\n",
            " 14  views               2 non-null      float64\n",
            "dtypes: float64(7), int64(1), object(7)\n",
            "memory usage: 852.0+ bytes\n",
            "None\n",
            "\n",
            "üíæ STEP 7: Saving Combined Dataset\n",
            "‚úÖ Combined data saved to instagram_combined_data_20250802_144246.csv\n",
            "   Save time: 0.001s\n",
            "   File size: 0.00 MB\n",
            "\n",
            "============================================================\n",
            "üìä DATA CONCATENATION PERFORMANCE REPORT\n",
            "============================================================\n",
            "‚è±Ô∏è Total Processing Time: 0.032 seconds\n",
            "üìÅ Files Loaded: 2\n",
            "\n",
            "üìÇ FILE LOADING PERFORMANCE:\n",
            "   Media: 0.003s (0.00 MB)\n",
            "   Stories: 0.001s (0.00 MB)\n",
            "\n",
            "üìä DATA PROCESSING METRICS:\n",
            "   Media Records: 4\n",
            "   Stories Records: 2\n",
            "   Combined Records: 6\n",
            "   Processing Time: 0.0014s\n",
            "\n",
            "üèõÔ∏è COLUMN STRUCTURE:\n",
            "   Media Columns: 11\n",
            "   Stories Columns: 11\n",
            "   Combined Columns: 15\n",
            "   Common Columns: 8\n",
            "\n",
            "üéØ DATA QUALITY METRICS:\n",
            "   Missing Values Created: 27\n",
            "   Duplicate Records: 0\n",
            "   Processing Rate: 4,253 records/second\n",
            "   Average Column Completeness: 70.0%\n",
            "\n",
            "‚úÖ No errors encountered during processing!\n",
            "============================================================\n",
            "\n",
            "üéâ Concatenation process completed successfully!\n",
            "üìä Final dataset shape: (6, 15)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# === DATA CONCATENATION PERFORMANCE TRACKING ===\n",
        "concatenation_stats = {\n",
        "    'start_time': time.time(),\n",
        "    'file_operations': {\n",
        "        'files_loaded': 0,\n",
        "        'load_times': {},\n",
        "        'file_sizes': {},\n",
        "        'load_errors': []\n",
        "    },\n",
        "    'data_processing': {\n",
        "        'total_records_media': 0,\n",
        "        'total_records_stories': 0,\n",
        "        'total_records_combined': 0,\n",
        "        'columns_media': 0,\n",
        "        'columns_stories': 0,\n",
        "        'columns_combined': 0,\n",
        "        'missing_values_created': 0,\n",
        "        'processing_time': 0\n",
        "    },\n",
        "    'data_quality': {\n",
        "        'duplicate_records': 0,\n",
        "        'data_completeness': {},\n",
        "        'column_overlap': [],\n",
        "        'unique_columns': []\n",
        "    }\n",
        "}\n",
        "\n",
        "def log_file_operation(operation, file_name, duration, success=True, error=None):\n",
        "    \"\"\"Log file loading operations\"\"\"\n",
        "    if success:\n",
        "        concatenation_stats['file_operations']['files_loaded'] += 1\n",
        "        concatenation_stats['file_operations']['load_times'][file_name] = duration\n",
        "        print(f\"‚úÖ {operation}: {file_name} loaded in {duration:.3f}s\")\n",
        "    else:\n",
        "        concatenation_stats['file_operations']['load_errors'].append({\n",
        "            'file': file_name,\n",
        "            'error': str(error),\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        print(f\"‚ùå {operation}: Failed to load {file_name} - {error}\")\n",
        "\n",
        "def analyze_dataframe(df, df_name):\n",
        "    \"\"\"Analyze dataframe properties\"\"\"\n",
        "    analysis = {\n",
        "        'name': df_name,\n",
        "        'rows': len(df),\n",
        "        'columns': len(df.columns),\n",
        "        'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024,\n",
        "        'null_values': df.isnull().sum().sum(),\n",
        "        'duplicate_rows': df.duplicated().sum(),\n",
        "        'column_list': df.columns.tolist(),\n",
        "        'dtypes': df.dtypes.to_dict()\n",
        "    }\n",
        "\n",
        "    print(f\"üìä {df_name} Analysis:\")\n",
        "    print(f\"   Rows: {analysis['rows']:,}\")\n",
        "    print(f\"   Columns: {analysis['columns']}\")\n",
        "    print(f\"   Memory Usage: {analysis['memory_usage_mb']:.2f} MB\")\n",
        "    print(f\"   Null Values: {analysis['null_values']:,}\")\n",
        "    print(f\"   Duplicate Rows: {analysis['duplicate_rows']}\")\n",
        "    print(f\"   Columns: {analysis['column_list']}\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "def main():\n",
        "    print(\"üîÑ Starting Instagram Data Concatenation Process\")\n",
        "    print(f\"‚è∞ Process started at: {datetime.now().isoformat()}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # === STEP 1: LOAD DATAFRAMES ===\n",
        "    print(\"\\nüìÇ STEP 1: Loading CSV Files\")\n",
        "\n",
        "    # Load media data\n",
        "    media_load_start = time.time()\n",
        "    try:\n",
        "        if os.path.exists('instagram_media_metrics.csv'):\n",
        "            df_media = pd.read_csv('instagram_media_metrics.csv')\n",
        "            media_load_time = time.time() - media_load_start\n",
        "            log_file_operation(\"Media Load\", \"instagram_media_metrics.csv\", media_load_time, True)\n",
        "\n",
        "            # Get file size\n",
        "            file_size_mb = os.path.getsize('instagram_media_metrics.csv') / 1024 / 1024\n",
        "            concatenation_stats['file_operations']['file_sizes']['media'] = file_size_mb\n",
        "\n",
        "        else:\n",
        "            raise FileNotFoundError(\"instagram_media_metrics.csv not found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        media_load_time = time.time() - media_load_start\n",
        "        log_file_operation(\"Media Load\", \"instagram_media_metrics.csv\", media_load_time, False, e)\n",
        "        return None\n",
        "\n",
        "    # Load stories data\n",
        "    stories_load_start = time.time()\n",
        "    try:\n",
        "        if os.path.exists('instagram_stories.csv'):\n",
        "            df_stories = pd.read_csv('instagram_stories.csv')\n",
        "            stories_load_time = time.time() - stories_load_start\n",
        "            log_file_operation(\"Stories Load\", \"instagram_stories.csv\", stories_load_time, True)\n",
        "\n",
        "            # Get file size\n",
        "            file_size_mb = os.path.getsize('instagram_stories.csv') / 1024 / 1024\n",
        "            concatenation_stats['file_operations']['file_sizes']['stories'] = file_size_mb\n",
        "\n",
        "        else:\n",
        "            raise FileNotFoundError(\"instagram_stories.csv not found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        stories_load_time = time.time() - stories_load_start\n",
        "        log_file_operation(\"Stories Load\", \"instagram_stories.csv\", stories_load_time, False, e)\n",
        "        return None\n",
        "\n",
        "    # === STEP 2: ANALYZE SOURCE DATA ===\n",
        "    print(\"\\nüìä STEP 2: Analyzing Source Data\")\n",
        "\n",
        "    media_analysis = analyze_dataframe(df_media, \"Media DataFrame\")\n",
        "    stories_analysis = analyze_dataframe(df_stories, \"Stories DataFrame\")\n",
        "\n",
        "    # Store in stats\n",
        "    concatenation_stats['data_processing']['total_records_media'] = len(df_media)\n",
        "    concatenation_stats['data_processing']['total_records_stories'] = len(df_stories)\n",
        "    concatenation_stats['data_processing']['columns_media'] = len(df_media.columns)\n",
        "    concatenation_stats['data_processing']['columns_stories'] = len(df_stories.columns)\n",
        "\n",
        "    # Analyze column overlap\n",
        "    media_cols = set(df_media.columns)\n",
        "    stories_cols = set(df_stories.columns)\n",
        "    common_cols = media_cols.intersection(stories_cols)\n",
        "    unique_media_cols = media_cols - stories_cols\n",
        "    unique_stories_cols = stories_cols - media_cols\n",
        "\n",
        "    concatenation_stats['data_quality']['column_overlap'] = list(common_cols)\n",
        "    concatenation_stats['data_quality']['unique_columns'] = {\n",
        "        'media_only': list(unique_media_cols),\n",
        "        'stories_only': list(unique_stories_cols)\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüîç Column Analysis:\")\n",
        "    print(f\"   Common columns: {len(common_cols)} - {list(common_cols)}\")\n",
        "    print(f\"   Media-only columns: {len(unique_media_cols)} - {list(unique_media_cols)}\")\n",
        "    print(f\"   Stories-only columns: {len(unique_stories_cols)} - {list(unique_stories_cols)}\")\n",
        "\n",
        "    # === STEP 3: ADD CATEGORY COLUMNS ===\n",
        "    print(\"\\nüè∑Ô∏è STEP 3: Adding Category Identifiers\")\n",
        "\n",
        "    category_start = time.time()\n",
        "    df_media['media_category'] = 'media'\n",
        "    df_stories['media_category'] = 'story'\n",
        "    category_time = time.time() - category_start\n",
        "\n",
        "    print(f\"‚úÖ Category columns added in {category_time:.4f}s\")\n",
        "\n",
        "    # === STEP 4: CONCATENATE DATAFRAMES ===\n",
        "    print(\"\\nüîó STEP 4: Concatenating DataFrames\")\n",
        "\n",
        "    concat_start = time.time()\n",
        "    try:\n",
        "        # Concatenate with detailed tracking\n",
        "        combined_df = pd.concat([df_media, df_stories], ignore_index=True, sort=False)\n",
        "        concat_time = time.time() - concat_start\n",
        "        concatenation_stats['data_processing']['processing_time'] = concat_time\n",
        "\n",
        "        print(f\"‚úÖ Concatenation completed in {concat_time:.4f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        concat_time = time.time() - concat_start\n",
        "        print(f\"‚ùå Concatenation failed after {concat_time:.4f}s: {e}\")\n",
        "        return None\n",
        "\n",
        "    # === STEP 5: ANALYZE COMBINED DATA ===\n",
        "    print(\"\\nüìà STEP 5: Analyzing Combined Dataset\")\n",
        "\n",
        "    combined_analysis = analyze_dataframe(combined_df, \"Combined DataFrame\")\n",
        "\n",
        "    # Store combined stats\n",
        "    concatenation_stats['data_processing']['total_records_combined'] = len(combined_df)\n",
        "    concatenation_stats['data_processing']['columns_combined'] = len(combined_df.columns)\n",
        "    concatenation_stats['data_processing']['missing_values_created'] = combined_df.isnull().sum().sum()\n",
        "\n",
        "    # Calculate data completeness for each column\n",
        "    completeness = {}\n",
        "    for col in combined_df.columns:\n",
        "        non_null_count = combined_df[col].notna().sum()\n",
        "        completeness[col] = (non_null_count / len(combined_df)) * 100\n",
        "\n",
        "    concatenation_stats['data_quality']['data_completeness'] = completeness\n",
        "\n",
        "    # Check for duplicates\n",
        "    concatenation_stats['data_quality']['duplicate_records'] = combined_df.duplicated().sum()\n",
        "\n",
        "    print(f\"\\nüìã Data Completeness by Column:\")\n",
        "    for col, comp_pct in sorted(completeness.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"   {col}: {comp_pct:.1f}%\")\n",
        "\n",
        "    # === STEP 6: DISPLAY RESULTS ===\n",
        "    print(\"\\nüìÑ STEP 6: Sample Data Preview\")\n",
        "    print(\"\\nFirst 5 rows of combined dataframe:\")\n",
        "    print(combined_df.head())\n",
        "\n",
        "    print(f\"\\nDataFrame Info:\")\n",
        "    print(combined_df.info())\n",
        "\n",
        "    # === STEP 7: SAVE COMBINED DATA ===\n",
        "    print(\"\\nüíæ STEP 7: Saving Combined Dataset\")\n",
        "\n",
        "    save_start = time.time()\n",
        "    try:\n",
        "        output_filename = f'instagram_combined_data_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
        "        combined_df.to_csv(output_filename, index=False)\n",
        "        save_time = time.time() - save_start\n",
        "\n",
        "        output_size_mb = os.path.getsize(output_filename) / 1024 / 1024\n",
        "        print(f\"‚úÖ Combined data saved to {output_filename}\")\n",
        "        print(f\"   Save time: {save_time:.3f}s\")\n",
        "        print(f\"   File size: {output_size_mb:.2f} MB\")\n",
        "\n",
        "    except Exception as e:\n",
        "        save_time = time.time() - save_start\n",
        "        print(f\"‚ùå Failed to save combined data after {save_time:.3f}s: {e}\")\n",
        "\n",
        "    # === GENERATE PERFORMANCE REPORT ===\n",
        "    generate_concatenation_report()\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def generate_concatenation_report():\n",
        "    \"\"\"Generate comprehensive performance report for data concatenation\"\"\"\n",
        "    total_duration = time.time() - concatenation_stats['start_time']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä DATA CONCATENATION PERFORMANCE REPORT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Overall performance\n",
        "    print(f\"‚è±Ô∏è Total Processing Time: {total_duration:.3f} seconds\")\n",
        "    print(f\"üìÅ Files Loaded: {concatenation_stats['file_operations']['files_loaded']}\")\n",
        "\n",
        "    # File loading performance\n",
        "    print(f\"\\nüìÇ FILE LOADING PERFORMANCE:\")\n",
        "    for file_name, load_time in concatenation_stats['file_operations']['load_times'].items():\n",
        "        file_type = 'Media' if 'media' in file_name else 'Stories'\n",
        "        size_mb = concatenation_stats['file_operations']['file_sizes'].get(file_type.lower(), 0)\n",
        "        print(f\"   {file_type}: {load_time:.3f}s ({size_mb:.2f} MB)\")\n",
        "\n",
        "    # Data processing metrics\n",
        "    print(f\"\\nüìä DATA PROCESSING METRICS:\")\n",
        "    print(f\"   Media Records: {concatenation_stats['data_processing']['total_records_media']:,}\")\n",
        "    print(f\"   Stories Records: {concatenation_stats['data_processing']['total_records_stories']:,}\")\n",
        "    print(f\"   Combined Records: {concatenation_stats['data_processing']['total_records_combined']:,}\")\n",
        "    print(f\"   Processing Time: {concatenation_stats['data_processing']['processing_time']:.4f}s\")\n",
        "\n",
        "    # Column analysis\n",
        "    print(f\"\\nüèõÔ∏è COLUMN STRUCTURE:\")\n",
        "    print(f\"   Media Columns: {concatenation_stats['data_processing']['columns_media']}\")\n",
        "    print(f\"   Stories Columns: {concatenation_stats['data_processing']['columns_stories']}\")\n",
        "    print(f\"   Combined Columns: {concatenation_stats['data_processing']['columns_combined']}\")\n",
        "    print(f\"   Common Columns: {len(concatenation_stats['data_quality']['column_overlap'])}\")\n",
        "\n",
        "    # Data quality metrics\n",
        "    print(f\"\\nüéØ DATA QUALITY METRICS:\")\n",
        "    print(f\"   Missing Values Created: {concatenation_stats['data_processing']['missing_values_created']:,}\")\n",
        "    print(f\"   Duplicate Records: {concatenation_stats['data_quality']['duplicate_records']}\")\n",
        "\n",
        "    # Performance insights\n",
        "    if concatenation_stats['data_processing']['total_records_combined'] > 0:\n",
        "        processing_rate = concatenation_stats['data_processing']['total_records_combined'] / concatenation_stats['data_processing']['processing_time']\n",
        "        print(f\"   Processing Rate: {processing_rate:,.0f} records/second\")\n",
        "\n",
        "    # Column completeness summary\n",
        "    if concatenation_stats['data_quality']['data_completeness']:\n",
        "        avg_completeness = sum(concatenation_stats['data_quality']['data_completeness'].values()) / len(concatenation_stats['data_quality']['data_completeness'])\n",
        "        print(f\"   Average Column Completeness: {avg_completeness:.1f}%\")\n",
        "\n",
        "    # Error summary\n",
        "    if concatenation_stats['file_operations']['load_errors']:\n",
        "        print(f\"\\nüö® ERRORS ENCOUNTERED:\")\n",
        "        for error in concatenation_stats['file_operations']['load_errors']:\n",
        "            print(f\"   {error['file']}: {error['error']}\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ No errors encountered during processing!\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return concatenation_stats\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Execute the concatenation process\n",
        "    result_df = main()\n",
        "\n",
        "    if result_df is not None:\n",
        "        print(f\"\\nüéâ Concatenation process completed successfully!\")\n",
        "        print(f\"üìä Final dataset shape: {result_df.shape}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Concatenation process failed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "2eHb4U-nUC35",
        "outputId": "c52680b9-b253-4b4f-8b62-248bfe705074"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        username                                          permalink  \\\n",
              "0  mnblanalytics        https://www.instagram.com/reel/DKWmrCONQqs/   \n",
              "1  mnblanalytics           https://www.instagram.com/p/DJ4VPz6tPPb/   \n",
              "2  mnblanalytics           https://www.instagram.com/p/DJb6pZWtXKt/   \n",
              "3  mnblanalytics           https://www.instagram.com/p/DJb6PloNTog/   \n",
              "4  mnblanalytics  https://instagram.com/stories/mnblanalytics/36...   \n",
              "5  mnblanalytics  https://instagram.com/stories/mnblanalytics/36...   \n",
              "\n",
              "                  id       caption                 timestamp media_type  \\\n",
              "0  18080236366793735      Testreel  2025-06-01T09:30:07+0000      VIDEO   \n",
              "1  18080278336761002  #Iniciative1  2025-05-20T15:20:22+0000      IMAGE   \n",
              "2  17904426585155969        Test 2  2025-05-09T14:29:12+0000      IMAGE   \n",
              "3  18079149412810358        Test 1  2025-05-09T14:25:41+0000      IMAGE   \n",
              "4  17929674428964127        TEST 3  2025-08-02T13:54:17+0000      IMAGE   \n",
              "5  18016504853574187          Test  2025-08-02T13:53:44+0000      IMAGE   \n",
              "\n",
              "   like_count  reach  video_views  plays   Platform media_category  replies  \\\n",
              "0         5.0    NaN          NaN    NaN  Instagram          media      NaN   \n",
              "1         5.0   32.0          NaN    NaN  Instagram          media      NaN   \n",
              "2         6.0   40.0          NaN    NaN  Instagram          media      NaN   \n",
              "3         7.0   38.0          NaN    NaN  Instagram          media      NaN   \n",
              "4         NaN    0.0          NaN    NaN  Instagram          story      0.0   \n",
              "5         NaN    0.0          NaN    NaN  Instagram          story      0.0   \n",
              "\n",
              "   total_interactions  views  \n",
              "0                 NaN    NaN  \n",
              "1                 NaN    NaN  \n",
              "2                 NaN    NaN  \n",
              "3                 NaN    NaN  \n",
              "4                 0.0    0.0  \n",
              "5                 0.0    0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7162fee4-eed9-426c-b218-e7123a829898\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>permalink</th>\n",
              "      <th>id</th>\n",
              "      <th>caption</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>media_type</th>\n",
              "      <th>like_count</th>\n",
              "      <th>reach</th>\n",
              "      <th>video_views</th>\n",
              "      <th>plays</th>\n",
              "      <th>Platform</th>\n",
              "      <th>media_category</th>\n",
              "      <th>replies</th>\n",
              "      <th>total_interactions</th>\n",
              "      <th>views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/reel/DKWmrCONQqs/</td>\n",
              "      <td>18080236366793735</td>\n",
              "      <td>Testreel</td>\n",
              "      <td>2025-06-01T09:30:07+0000</td>\n",
              "      <td>VIDEO</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>media</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/p/DJ4VPz6tPPb/</td>\n",
              "      <td>18080278336761002</td>\n",
              "      <td>#Iniciative1</td>\n",
              "      <td>2025-05-20T15:20:22+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>media</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/p/DJb6pZWtXKt/</td>\n",
              "      <td>17904426585155969</td>\n",
              "      <td>Test 2</td>\n",
              "      <td>2025-05-09T14:29:12+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>media</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://www.instagram.com/p/DJb6PloNTog/</td>\n",
              "      <td>18079149412810358</td>\n",
              "      <td>Test 1</td>\n",
              "      <td>2025-05-09T14:25:41+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>7.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>media</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://instagram.com/stories/mnblanalytics/36...</td>\n",
              "      <td>17929674428964127</td>\n",
              "      <td>TEST 3</td>\n",
              "      <td>2025-08-02T13:54:17+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>story</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mnblanalytics</td>\n",
              "      <td>https://instagram.com/stories/mnblanalytics/36...</td>\n",
              "      <td>18016504853574187</td>\n",
              "      <td>Test</td>\n",
              "      <td>2025-08-02T13:53:44+0000</td>\n",
              "      <td>IMAGE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Instagram</td>\n",
              "      <td>story</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7162fee4-eed9-426c-b218-e7123a829898')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7162fee4-eed9-426c-b218-e7123a829898 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7162fee4-eed9-426c-b218-e7123a829898');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f9f8b96c-e95e-40fb-a959-cbf431d34041\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9f8b96c-e95e-40fb-a959-cbf431d34041')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f9f8b96c-e95e-40fb-a959-cbf431d34041 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0e7c44f1-0f60-4dd5-b2dc-50cd66b78f7b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e7c44f1-0f60-4dd5-b2dc-50cd66b78f7b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mnblanalytics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"permalink\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"https://www.instagram.com/reel/DKWmrCONQqs/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80176527170021,\n        \"min\": 17904426585155969,\n        \"max\": 18080278336761002,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          18080236366793735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Testreel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2025-06-01T09:30:07+0000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"media_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"IMAGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"like_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9574271077563381,\n        \"min\": 5.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.29778313018444,\n        \"min\": 0.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Platform\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"media_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"replies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_interactions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"views\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "combined_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCcgb_2cIb9Z"
      },
      "source": [
        "## Generate DDBB in Big Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fOlyAgh6IbHg",
        "outputId": "e9aa0dca-e785-48db-cab5-ab5c56f92903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.11/dist-packages (3.35.1)\n",
            "Requirement already satisfied: pandas-gbq in /usr/local/lib/python3.11/dist-packages (0.29.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.38.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (25.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (75.2.0)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (18.1.0)\n",
            "Requirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (1.9.1)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq) (1.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (2.0.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.7.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade google-cloud-bigquery pandas-gbq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plhUL77EI2Ks"
      },
      "source": [
        "### Authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8itt8BHHIoeb"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSS1ErvGI4Y4"
      },
      "source": [
        "### Upload IG Data Frame to Big Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n9Vh6ySDIzo3",
        "outputId": "75ebd136-fa0d-4763-e758-b805ce29095e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting upload of 6 rows to BigQuery...\n",
            "Target: proof-of-brand.social_media_metrics.instagram_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas_gbq/gbq.py:528: FutureWarning: verbose is deprecated and will be removed in a future version. Set logging level in order to vary verbosity\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1999.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload completed in 3.34 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "from pandas_gbq import to_gbq\n",
        "import time\n",
        "\n",
        "project_id = \"proof-of-brand\"\n",
        "dataset_id = \"social_media_metrics\"\n",
        "table_id = \"instagram_data\"\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "print(f\"Starting upload of {len(combined_df)} rows to BigQuery...\")\n",
        "print(f\"Target: {project_id}.{dataset_id}.{table_id}\")\n",
        "\n",
        "to_gbq(\n",
        "    combined_df,\n",
        "    f\"{dataset_id}.{table_id}\",\n",
        "    project_id=project_id,\n",
        "    if_exists='replace',\n",
        "    verbose=True,  # This shows progress updates\n",
        "    progress_bar=True  # Shows a progress bar\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Upload completed in {end_time - start_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4Kt-s2X5MS"
      },
      "source": [
        "### X API Connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RClo-YWTaCwK"
      },
      "source": [
        "### Define X Bearer Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gbHHAGKxZ-5i"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Replace with your own X Bearer Token\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAABpl1wEAAAAA29Dr%2F5hqGWc0xSZ8uMZqEi3nmdQ%3DuxcTuvO2rqyE4ozsLTInBK6Sx6YIK6MRXFo7mcSd2SJokjIKOk\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIPgFiLDNrZ7"
      },
      "source": [
        "### Retrieve tweets by API Connection by tweet id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WS_CCD9ccKrS",
        "outputId": "0579bcfc-02b6-416b-8e47-fc7a5df3d0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit hit. Retrying in 615 seconds...\n",
            "Tweet ID: 1924504474158006284\n",
            "  Likes: 1\n",
            "  Retweets: 0\n",
            "  Replies: 0\n",
            "  Quotes: 0\n",
            "\n",
            "Tweet ID: 1924505694553641438\n",
            "  Likes: 0\n",
            "  Retweets: 0\n",
            "  Replies: 0\n",
            "  Quotes: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_tweet_metrics(tweet_ids, max_retries=5):\n",
        "    url = \"https://api.twitter.com/2/tweets\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
        "    }\n",
        "\n",
        "    params = {\n",
        "        \"ids\": \",\".join(tweet_ids),\n",
        "        \"tweet.fields\": \"public_metrics\"\n",
        "    }\n",
        "\n",
        "    retries = 0\n",
        "    while retries <= max_retries:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "\n",
        "        elif response.status_code == 429:\n",
        "            # Too many requests ‚Äî wait and retry\n",
        "            wait_time = int(response.headers.get(\"x-rate-limit-reset\", time.time() + 60)) - int(time.time())\n",
        "            wait_time = max(wait_time, 5)  # Minimum wait time\n",
        "            print(f\"Rate limit hit. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "            retries += 1\n",
        "\n",
        "        else:\n",
        "            # Other errors ‚Äî stop\n",
        "            raise Exception(f\"Request failed: {response.status_code} - {response.text}\")\n",
        "\n",
        "    raise Exception(\"Max retries exceeded.\")\n",
        "\n",
        "# Example usage\n",
        "tweet_ids = ['1924504474158006284', '1924505694553641438']  # Up to 100 tweet IDs\n",
        "metrics = get_tweet_metrics(tweet_ids)\n",
        "\n",
        "# Display metrics\n",
        "for tweet in metrics.get(\"data\", []):\n",
        "    print(f\"Tweet ID: {tweet['id']}\")\n",
        "    print(f\"  Likes: {tweet['public_metrics']['like_count']}\")\n",
        "    print(f\"  Retweets: {tweet['public_metrics']['retweet_count']}\")\n",
        "    print(f\"  Replies: {tweet['public_metrics']['reply_count']}\")\n",
        "    print(f\"  Quotes: {tweet['public_metrics']['quote_count']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0otzh5mcNjgZ"
      },
      "source": [
        "### Retrieve all tweets from a particular X account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9SV7cQJqMij8",
        "outputId": "177e9ca5-0291-456e-ffb2-bc78bd88583c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üöÄ TWITTER DATA COLLECTION STARTED\n",
            "============================================================\n",
            "üîç Initial memory usage: 1878.62 MB\n",
            "üéØ Target username: @mnblanalytics\n",
            "üîç Looking up user ID for: @mnblanalytics\n",
            "‚úÖ Found user ID: 1924492647856578560 (took 0.10s)\n",
            "\n",
            "üê¶ Starting tweet collection for user ID: 1924492647856578560\n",
            "üìä Max results per request: 100\n",
            "\n",
            "üì° API Request #1\n",
            "Response: 200 (took 0.10s)\n",
            "üì• Retrieved 2 tweets (Total: 2)\n",
            "üîÑ Rate limit: 0 requests remaining\n",
            "‚úÖ No more tweets to fetch\n",
            "\n",
            "üèÅ Tweet collection completed!\n",
            "üìä Total tweets collected: 2\n",
            "‚è±Ô∏è  Total time: 0.10s\n",
            "üì° API requests made: 1\n",
            "üìà Average tweets per request: 2.0\n",
            "\n",
            "üìã Converting 2 tweets to DataFrame...\n",
            "‚úÖ DataFrame created in 0.00s\n",
            "üìä Shape: (2, 8)\n",
            "üíæ Memory usage: 0.00 MB\n",
            "üìà Total engagement: 1\n",
            "üìä Average engagement per tweet: 0.5\n",
            "\n",
            "============================================================\n",
            "üéâ COLLECTION COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "‚è±Ô∏è  Total execution time: 0.21s\n",
            "üìä Final dataset: 2 tweets, 8 columns\n",
            "üíæ Memory increase: +0.00 MB\n",
            "üìà Processing rate: 9.7 tweets/second\n",
            "\n",
            "üìã DATASET PREVIEW:\n",
            "----------------------------------------\n",
            "              tweet_id                              text  \\\n",
            "0  1924505694553641438  This is a test Tweet! Second Try   \n",
            "1  1924504474158006284             This is a test Tweet!   \n",
            "\n",
            "                 created_at  like_count  retweet_count  reply_count  \\\n",
            "0  2025-05-19T16:41:27.000Z           0              0            0   \n",
            "1  2025-05-19T16:36:36.000Z           1              0            0   \n",
            "\n",
            "   quote_count Platform  \n",
            "0            0        X  \n",
            "1            0        X  \n",
            "\n",
            "üìä TOP PERFORMING TWEETS:\n",
            "----------------------------------------\n",
            "ID: 1924504474158006284 | Engagement: 1\n",
            "Text: This is a test Tweet!...\n",
            "\n",
            "ID: 1924505694553641438 | Engagement: 0\n",
            "Text: This is a test Tweet! Second Try...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "\n",
        "# === Step 1: Twitter Bearer Token ===\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAABpl1wEAAAAA29Dr%2F5hqGWc0xSZ8uMZqEi3nmdQ%3DuxcTuvO2rqyE4ozsLTInBK6Sx6YIK6MRXFo7mcSd2SJokjIKOk\"\n",
        "\n",
        "def get_user_id(username):\n",
        "    print(f\"üîç Looking up user ID for: @{username}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    url = f\"https://api.twitter.com/2/users/by/username/{username}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"}\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        user_id = response.json()[\"data\"][\"id\"]\n",
        "        print(f\"‚úÖ Found user ID: {user_id} (took {duration:.2f}s)\")\n",
        "        return user_id\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to get user ID: {response.status_code} - {response.text}\")\n",
        "        raise Exception(f\"Failed to get user ID: {response.status_code} - {response.text}\")\n",
        "\n",
        "def get_all_tweets(user_id, max_results=100):\n",
        "    print(f\"\\nüê¶ Starting tweet collection for user ID: {user_id}\")\n",
        "    print(f\"üìä Max results per request: {max_results}\")\n",
        "\n",
        "    url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
        "    headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"}\n",
        "    params = {\n",
        "        \"tweet.fields\": \"public_metrics,created_at\",\n",
        "        \"max_results\": max_results\n",
        "    }\n",
        "\n",
        "    all_tweets = []\n",
        "    next_token = None\n",
        "    request_count = 0\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "        request_count += 1\n",
        "        print(f\"\\nüì° API Request #{request_count}\")\n",
        "\n",
        "        if next_token:\n",
        "            params[\"pagination_token\"] = next_token\n",
        "            print(f\"üîó Using pagination token: {next_token[:20]}...\")\n",
        "\n",
        "        request_start = time.time()\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        request_duration = time.time() - request_start\n",
        "\n",
        "        print(f\"Response: {response.status_code} (took {request_duration:.2f}s)\")\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            batch_tweets = data.get(\"data\", [])\n",
        "            all_tweets.extend(batch_tweets)\n",
        "\n",
        "            print(f\"üì• Retrieved {len(batch_tweets)} tweets (Total: {len(all_tweets)})\")\n",
        "\n",
        "            # Rate limit info\n",
        "            remaining = response.headers.get(\"x-rate-limit-remaining\", \"Unknown\")\n",
        "            reset_time = response.headers.get(\"x-rate-limit-reset\", \"Unknown\")\n",
        "            print(f\"üîÑ Rate limit: {remaining} requests remaining\")\n",
        "\n",
        "            next_token = data.get(\"meta\", {}).get(\"next_token\")\n",
        "            if not next_token:\n",
        "                print(\"‚úÖ No more tweets to fetch\")\n",
        "                break\n",
        "\n",
        "            print(\"‚è∏Ô∏è  Waiting 1s before next request...\")\n",
        "            time.sleep(1)\n",
        "\n",
        "        elif response.status_code == 429:\n",
        "            wait_time = int(response.headers.get(\"x-rate-limit-reset\", time.time() + 60)) - int(time.time())\n",
        "            wait_time = max(wait_time, 5)\n",
        "            print(f\"‚è≥ Rate limit hit. Waiting {wait_time} seconds...\")\n",
        "            print(f\"Reset time: {datetime.fromtimestamp(int(response.headers.get('x-rate-limit-reset', time.time())))}\")\n",
        "            time.sleep(wait_time)\n",
        "        else:\n",
        "            print(f\"‚ùå API Error: {response.status_code} - {response.text}\")\n",
        "            raise Exception(f\"Failed to get tweets: {response.status_code} - {response.text}\")\n",
        "\n",
        "    total_duration = time.time() - total_start_time\n",
        "    print(f\"\\nüèÅ Tweet collection completed!\")\n",
        "    print(f\"üìä Total tweets collected: {len(all_tweets)}\")\n",
        "    print(f\"‚è±Ô∏è  Total time: {total_duration:.2f}s\")\n",
        "    print(f\"üì° API requests made: {request_count}\")\n",
        "    print(f\"üìà Average tweets per request: {len(all_tweets)/request_count:.1f}\")\n",
        "\n",
        "    return all_tweets\n",
        "\n",
        "def tweets_to_dataframe(tweets):\n",
        "    print(f\"\\nüìã Converting {len(tweets)} tweets to DataFrame...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    df = pd.DataFrame([\n",
        "        {\n",
        "            \"tweet_id\": tweet[\"id\"],\n",
        "            \"text\": tweet[\"text\"],\n",
        "            \"created_at\": tweet[\"created_at\"],\n",
        "            \"like_count\": tweet[\"public_metrics\"][\"like_count\"],\n",
        "            \"retweet_count\": tweet[\"public_metrics\"][\"retweet_count\"],\n",
        "            \"reply_count\": tweet[\"public_metrics\"][\"reply_count\"],\n",
        "            \"quote_count\": tweet[\"public_metrics\"][\"quote_count\"],\n",
        "            \"Platform\": \"X\",\n",
        "        }\n",
        "        for tweet in tweets\n",
        "    ])\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    memory_usage = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "    print(f\"‚úÖ DataFrame created in {duration:.2f}s\")\n",
        "    print(f\"üìä Shape: {df.shape}\")\n",
        "    print(f\"üíæ Memory usage: {memory_usage:.2f} MB\")\n",
        "\n",
        "    # Show engagement stats\n",
        "    total_engagement = df[['like_count', 'retweet_count', 'reply_count', 'quote_count']].sum().sum()\n",
        "    avg_engagement = total_engagement / len(df)\n",
        "    print(f\"üìà Total engagement: {total_engagement:,}\")\n",
        "    print(f\"üìä Average engagement per tweet: {avg_engagement:.1f}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# === Step 2: Main execution with comprehensive logging ===\n",
        "print(\"=\" * 60)\n",
        "print(\"üöÄ TWITTER DATA COLLECTION STARTED\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Monitor system resources\n",
        "process = psutil.Process()\n",
        "memory_start = process.memory_info().rss / 1024**2\n",
        "print(f\"üîç Initial memory usage: {memory_start:.2f} MB\")\n",
        "\n",
        "overall_start = time.time()\n",
        "\n",
        "try:\n",
        "    username = \"mnblanalytics\"\n",
        "    print(f\"üéØ Target username: @{username}\")\n",
        "\n",
        "    # Step 1: Get user ID\n",
        "    user_id = get_user_id(username)\n",
        "\n",
        "    # Step 2: Get all tweets\n",
        "    tweets = get_all_tweets(user_id)\n",
        "\n",
        "    # Step 3: Convert to DataFrame\n",
        "    df_tweets = tweets_to_dataframe(tweets)\n",
        "\n",
        "    # Final stats\n",
        "    overall_duration = time.time() - overall_start\n",
        "    memory_end = process.memory_info().rss / 1024**2\n",
        "    memory_increase = memory_end - memory_start\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üéâ COLLECTION COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"‚è±Ô∏è  Total execution time: {overall_duration:.2f}s\")\n",
        "    print(f\"üìä Final dataset: {df_tweets.shape[0]} tweets, {df_tweets.shape[1]} columns\")\n",
        "    print(f\"üíæ Memory increase: +{memory_increase:.2f} MB\")\n",
        "    print(f\"üìà Processing rate: {len(tweets)/overall_duration:.1f} tweets/second\")\n",
        "\n",
        "    # Preview with engagement metrics\n",
        "    print(f\"\\nüìã DATASET PREVIEW:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(df_tweets.head())\n",
        "\n",
        "    print(f\"\\nüìä TOP PERFORMING TWEETS:\")\n",
        "    print(\"-\" * 40)\n",
        "    df_tweets['total_engagement'] = df_tweets[['like_count', 'retweet_count', 'reply_count', 'quote_count']].sum(axis=1)\n",
        "    top_tweets = df_tweets.nlargest(3, 'total_engagement')[['tweet_id', 'text', 'total_engagement']]\n",
        "    for _, tweet in top_tweets.iterrows():\n",
        "        print(f\"ID: {tweet['tweet_id']} | Engagement: {tweet['total_engagement']:,}\")\n",
        "        print(f\"Text: {tweet['text'][:100]}...\")\n",
        "        print()\n",
        "\n",
        "except Exception as e:\n",
        "    overall_duration = time.time() - overall_start\n",
        "    memory_end = process.memory_info().rss / 1024**2\n",
        "\n",
        "    print(f\"\\n‚ùå EXECUTION FAILED after {overall_duration:.2f}s\")\n",
        "    print(f\"üíæ Memory at failure: {memory_end:.2f} MB\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiII5S-AY7Th"
      },
      "outputs": [],
      "source": [
        "#Add permalink, platform, username, followers, media_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBLm9SmSO0QC"
      },
      "source": [
        "### Generate X DDBB into Big Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GlpQFA-0PF93",
        "outputId": "be62387e-f107-4a58-fc0a-bbe9a7ac9f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üì§ BIGQUERY UPLOAD STARTED\n",
            "============================================================\n",
            "üîç Memory before upload: 1878.62 MB\n",
            "\n",
            "üìä DATASET ANALYSIS:\n",
            "------------------------------\n",
            "Shape: 2 rows √ó 9 columns\n",
            "Memory usage: 0.00 MB\n",
            "Target table: proof-of-brand.social_media_metrics.tweets_data\n",
            "\n",
            "üìã DATA TYPES:\n",
            "  tweet_id: object (0 nulls)\n",
            "  text: object (0 nulls)\n",
            "  created_at: object (0 nulls)\n",
            "  like_count: int64 (0 nulls)\n",
            "  retweet_count: int64 (0 nulls)\n",
            "  reply_count: int64 (0 nulls)\n",
            "  quote_count: int64 (0 nulls)\n",
            "  Platform: object (0 nulls)\n",
            "  total_engagement: int64 (0 nulls)\n",
            "\n",
            "üîç DATA QUALITY CHECK:\n",
            "  Duplicate rows: 0\n",
            "  Date range: 2025-05-19T16:36:36.000Z to 2025-05-19T16:41:27.000Z\n",
            "\n",
            "üöÄ Starting upload at 15:16:38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas_gbq/gbq.py:528: FutureWarning: verbose is deprecated and will be removed in a future version. Set logging level in order to vary verbosity\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 2045.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ UPLOAD SUCCESSFUL!\n",
            "========================================\n",
            "‚è±Ô∏è  Upload time: 3.60 seconds\n",
            "üìä Rows uploaded: 2\n",
            "üìà Upload rate: 0.6 rows/second\n",
            "üíæ Memory change: +0.00 MB\n",
            "üì¶ Data size: 0.00 MB\n",
            "üìà Total engagement uploaded: 1\n",
            "\n",
            "üéØ Table location: https://console.cloud.google.com/bigquery?project=proof-of-brand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "from pandas_gbq import to_gbq\n",
        "import time\n",
        "import psutil\n",
        "from datetime import datetime\n",
        "\n",
        "project_id = \"proof-of-brand\"\n",
        "dataset_id = \"social_media_metrics\"\n",
        "table_id_tweets = \"tweets_data\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üì§ BIGQUERY UPLOAD STARTED\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Monitor system resources\n",
        "process = psutil.Process()\n",
        "memory_before = process.memory_info().rss / 1024**2\n",
        "print(f\"üîç Memory before upload: {memory_before:.2f} MB\")\n",
        "\n",
        "# Analyze DataFrame before upload\n",
        "print(f\"\\nüìä DATASET ANALYSIS:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Shape: {df_tweets.shape[0]} rows √ó {df_tweets.shape[1]} columns\")\n",
        "print(f\"Memory usage: {df_tweets.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(f\"Target table: {project_id}.{dataset_id}.{table_id_tweets}\")\n",
        "\n",
        "# Show data types and potential issues\n",
        "print(f\"\\nüìã DATA TYPES:\")\n",
        "for col, dtype in df_tweets.dtypes.items():\n",
        "    null_count = df_tweets[col].isnull().sum()\n",
        "    print(f\"  {col}: {dtype} ({null_count} nulls)\")\n",
        "\n",
        "# Check for any data quality issues\n",
        "print(f\"\\nüîç DATA QUALITY CHECK:\")\n",
        "duplicate_rows = df_tweets.duplicated().sum()\n",
        "print(f\"  Duplicate rows: {duplicate_rows}\")\n",
        "print(f\"  Date range: {df_tweets['created_at'].min()} to {df_tweets['created_at'].max()}\")\n",
        "\n",
        "# Start upload with timing\n",
        "print(f\"\\nüöÄ Starting upload at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "upload_start = time.time()\n",
        "\n",
        "try:\n",
        "    # Upload with verbose output\n",
        "    to_gbq(\n",
        "        df_tweets,\n",
        "        f\"{dataset_id}.{table_id_tweets}\",\n",
        "        project_id=project_id,\n",
        "        if_exists='replace',\n",
        "        verbose=True,  # Shows progress\n",
        "        progress_bar=True  # Shows progress bar\n",
        "    )\n",
        "\n",
        "    upload_duration = time.time() - upload_start\n",
        "    memory_after = process.memory_info().rss / 1024**2\n",
        "    memory_change = memory_after - memory_before\n",
        "\n",
        "    # Success metrics\n",
        "    print(f\"\\n‚úÖ UPLOAD SUCCESSFUL!\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"‚è±Ô∏è  Upload time: {upload_duration:.2f} seconds\")\n",
        "    print(f\"üìä Rows uploaded: {df_tweets.shape[0]:,}\")\n",
        "    print(f\"üìà Upload rate: {df_tweets.shape[0]/upload_duration:.1f} rows/second\")\n",
        "    print(f\"üíæ Memory change: {memory_change:+.2f} MB\")\n",
        "    print(f\"üì¶ Data size: {df_tweets.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "    # Calculate some engagement stats for the upload\n",
        "    total_engagement = df_tweets[['like_count', 'retweet_count', 'reply_count', 'quote_count']].sum().sum()\n",
        "    print(f\"üìà Total engagement uploaded: {total_engagement:,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    upload_duration = time.time() - upload_start\n",
        "    memory_after = process.memory_info().rss / 1024**2\n",
        "\n",
        "    print(f\"\\n‚ùå UPLOAD FAILED after {upload_duration:.2f}s\")\n",
        "    print(f\"üíæ Memory at failure: {memory_after:.2f} MB\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "print(f\"\\nüéØ Table location: https://console.cloud.google.com/bigquery?project={project_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xSHK8jkX7hK"
      },
      "source": [
        "### X Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g91X7cLeHkAZ",
        "outputId": "17b0a761-eafc-42fd-9d11-ec05d6122a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üß† SENTIMENT ANALYSIS PIPELINE STARTED\n",
            "============================================================\n",
            "üîç Initial memory usage: 1878.62 MB\n",
            "\n",
            "üîß SETTING UP TWITTER API\n",
            "------------------------------\n",
            "üîë Bearer token configured: AAAAAAAAAAAAAAAAAAAA...\n",
            "‚úÖ API client initialized in 0.00s\n",
            "\n",
            "üîç FETCHING TWEETS\n",
            "------------------------------\n",
            "üéØ Query: (\"Fintual\" OR \"#Fintual\") lang:en -is:retweet\n",
            "üìä Max results: 10\n",
            "üöÄ Starting tweet search at 15:17:53\n",
            "‚úÖ Search completed in 0.13s\n",
            "üì• Retrieved 1 tweets\n",
            "üìù Average tweet length: 228.0 characters\n",
            "\n",
            "üßπ TWEET CLEANING\n",
            "------------------------------\n",
            "‚úÖ Cleaned 1 tweets in 0.000s\n",
            "üìä Average character reduction: 30.0\n",
            "\n",
            "ü§ñ LOADING SENTIMENT MODEL\n",
            "------------------------------\n",
            "üì¶ Model: cardiffnlp/twitter-roberta-base-sentiment\n",
            "üîÑ Loading tokenizer...\n",
            "üîÑ Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded in 1.44s\n",
            "üíæ Model memory usage: +204.73 MB\n",
            "üè∑Ô∏è  Labels: ['Negative', 'Neutral', 'Positive']\n",
            "\n",
            "üé≠ SENTIMENT ANALYSIS\n",
            "------------------------------\n",
            "üöÄ Starting analysis of 1 tweets...\n",
            "  Processing tweet 1/1... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive (0.990) - 0.305s\n",
            "\n",
            "üìä ANALYSIS COMPLETE!\n",
            "========================================\n",
            "‚è±Ô∏è  Total execution time: 1.88s\n",
            "üé≠ Analysis time: 0.31s\n",
            "üìà Average prediction time: 0.305s\n",
            "üíæ Total memory usage: 2074.42 MB (+195.79 MB)\n",
            "\n",
            "üìä SENTIMENT DISTRIBUTION:\n",
            "------------------------------\n",
            "  Positive: 1 tweets (100.0%)\n",
            "\n",
            "üéØ Average confidence: 0.990\n",
            "\n",
            "üìã RESULTS PREVIEW:\n",
            "----------------------------------------\n",
            "                                               tweet sentiment  confidence\n",
            "0  160 confirmed attendees, 500+ registrations. I...  Positive        0.99\n",
            "\n",
            "üèÜ MOST CONFIDENT PREDICTIONS:\n",
            "----------------------------------------\n",
            "Sentiment: Positive (confidence: 0.99)\n",
            "Tweet: 160 confirmed attendees, 500+ registrations. I'm excited to launch our AI community in CDMX. Gratefu...\n",
            "\n",
            "\n",
            "‚úÖ Pipeline completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "import time\n",
        "import psutil\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üß† SENTIMENT ANALYSIS PIPELINE STARTED\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Monitor system resources\n",
        "process = psutil.Process()\n",
        "memory_start = process.memory_info().rss / 1024**2\n",
        "print(f\"üîç Initial memory usage: {memory_start:.2f} MB\")\n",
        "\n",
        "overall_start = time.time()\n",
        "\n",
        "# ------------------------------\n",
        "# 1. SETUP: Twitter API\n",
        "# ------------------------------\n",
        "print(f\"\\nüîß SETTING UP TWITTER API\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "bearer_token = BEARER_TOKEN\n",
        "print(f\"üîë Bearer token configured: {bearer_token[:20]}...\")\n",
        "\n",
        "api_start = time.time()\n",
        "client = tweepy.Client(bearer_token=bearer_token, wait_on_rate_limit=True)\n",
        "api_duration = time.time() - api_start\n",
        "print(f\"‚úÖ API client initialized in {api_duration:.2f}s\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2. QUERY & FETCH TWEETS\n",
        "# ------------------------------\n",
        "print(f\"\\nüîç FETCHING TWEETS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "query = '(\"Fintual\" OR \"#Fintual\") lang:en -is:retweet'\n",
        "max_results = 10\n",
        "\n",
        "print(f\"üéØ Query: {query}\")\n",
        "print(f\"üìä Max results: {max_results}\")\n",
        "\n",
        "fetch_start = time.time()\n",
        "\n",
        "try:\n",
        "    print(f\"üöÄ Starting tweet search at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    response = client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=['text'])\n",
        "    fetch_duration = time.time() - fetch_start\n",
        "\n",
        "    tweets = [tweet.text for tweet in response.data] if response.data else []\n",
        "\n",
        "    print(f\"‚úÖ Search completed in {fetch_duration:.2f}s\")\n",
        "    print(f\"üì• Retrieved {len(tweets)} tweets\")\n",
        "\n",
        "    if tweets:\n",
        "        avg_length = sum(len(tweet) for tweet in tweets) / len(tweets)\n",
        "        print(f\"üìù Average tweet length: {avg_length:.1f} characters\")\n",
        "\n",
        "except tweepy.errors.TooManyRequests as e:\n",
        "    fetch_duration = time.time() - fetch_start\n",
        "    print(f\"‚è≥ Rate limit hit after {fetch_duration:.2f}s: {e}\")\n",
        "    print(\"üîÑ Waiting 60s before retry...\")\n",
        "    time.sleep(60)\n",
        "\n",
        "    retry_start = time.time()\n",
        "    response = client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=['text'])\n",
        "    retry_duration = time.time() - retry_start\n",
        "\n",
        "    tweets = [tweet.text for tweet in response.data] if response.data else []\n",
        "    print(f\"‚úÖ Retry successful in {retry_duration:.2f}s\")\n",
        "    print(f\"üì• Retrieved {len(tweets)} tweets\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3. CLEANING FUNCTION\n",
        "# ------------------------------\n",
        "print(f\"\\nüßπ TWEET CLEANING\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    original_length = len(tweet)\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)  # remove URLs\n",
        "    tweet = re.sub(r\"@\\w+\", \"\", tweet)     # remove mentions\n",
        "    tweet = re.sub(r\"#\", \"\", tweet)        # remove hashtag symbol\n",
        "    tweet = re.sub(r\"\\s+\", \" \", tweet).strip()\n",
        "    cleaned_length = len(tweet)\n",
        "    return tweet, original_length, cleaned_length\n",
        "\n",
        "# Clean all tweets and track statistics\n",
        "cleaning_start = time.time()\n",
        "cleaning_stats = []\n",
        "\n",
        "for i, tweet in enumerate(tweets):\n",
        "    clean_text, orig_len, clean_len = clean_tweet(tweet)\n",
        "    tweets[i] = clean_text  # Update the original list\n",
        "    cleaning_stats.append({\n",
        "        'original_length': orig_len,\n",
        "        'cleaned_length': clean_len,\n",
        "        'reduction': orig_len - clean_len\n",
        "    })\n",
        "\n",
        "cleaning_duration = time.time() - cleaning_start\n",
        "\n",
        "if cleaning_stats:\n",
        "    avg_reduction = sum(stat['reduction'] for stat in cleaning_stats) / len(cleaning_stats)\n",
        "    print(f\"‚úÖ Cleaned {len(tweets)} tweets in {cleaning_duration:.3f}s\")\n",
        "    print(f\"üìä Average character reduction: {avg_reduction:.1f}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. LOAD SENTIMENT MODEL\n",
        "# ------------------------------\n",
        "print(f\"\\nü§ñ LOADING SENTIMENT MODEL\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "print(f\"üì¶ Model: {MODEL}\")\n",
        "\n",
        "model_start = time.time()\n",
        "\n",
        "print(\"üîÑ Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "print(\"üîÑ Loading model...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "model_duration = time.time() - model_start\n",
        "memory_after_model = process.memory_info().rss / 1024**2\n",
        "model_memory = memory_after_model - memory_start\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "print(f\"‚úÖ Model loaded in {model_duration:.2f}s\")\n",
        "print(f\"üíæ Model memory usage: +{model_memory:.2f} MB\")\n",
        "print(f\"üè∑Ô∏è  Labels: {labels}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. PREDICT SENTIMENTS\n",
        "# ------------------------------\n",
        "print(f\"\\nüé≠ SENTIMENT ANALYSIS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "def get_sentiment(text):\n",
        "    start_time = time.time()\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "\n",
        "    scores = output.logits[0].numpy()\n",
        "    scores = softmax(scores)\n",
        "    sentiment = labels[scores.argmax()]\n",
        "    confidence = scores.max()\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    return sentiment, float(confidence), duration\n",
        "\n",
        "# ------------------------------\n",
        "# 6. ANALYZE AND OUTPUT RESULTS\n",
        "# ------------------------------\n",
        "print(f\"üöÄ Starting analysis of {len(tweets)} tweets...\")\n",
        "\n",
        "analysis_start = time.time()\n",
        "results = []\n",
        "prediction_times = []\n",
        "\n",
        "for i, tweet in enumerate(tweets, 1):\n",
        "    print(f\"  Processing tweet {i}/{len(tweets)}...\", end=\" \")\n",
        "\n",
        "    sentiment, confidence, pred_time = get_sentiment(tweet)\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    results.append({\n",
        "        'tweet': tweet,\n",
        "        'sentiment': sentiment,\n",
        "        'confidence': round(confidence, 3)\n",
        "    })\n",
        "\n",
        "    print(f\"{sentiment} ({confidence:.3f}) - {pred_time:.3f}s\")\n",
        "\n",
        "analysis_duration = time.time() - analysis_start\n",
        "overall_duration = time.time() - overall_start\n",
        "memory_final = process.memory_info().rss / 1024**2\n",
        "\n",
        "# Create DataFrame and show results\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\nüìä ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"‚è±Ô∏è  Total execution time: {overall_duration:.2f}s\")\n",
        "print(f\"üé≠ Analysis time: {analysis_duration:.2f}s\")\n",
        "print(f\"üìà Average prediction time: {sum(prediction_times)/len(prediction_times):.3f}s\")\n",
        "print(f\"üíæ Total memory usage: {memory_final:.2f} MB (+{memory_final - memory_start:.2f} MB)\")\n",
        "\n",
        "# Sentiment distribution\n",
        "if not df.empty:\n",
        "    sentiment_counts = df['sentiment'].value_counts()\n",
        "    print(f\"\\nüìä SENTIMENT DISTRIBUTION:\")\n",
        "    print(\"-\" * 30)\n",
        "    for sentiment, count in sentiment_counts.items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"  {sentiment}: {count} tweets ({percentage:.1f}%)\")\n",
        "\n",
        "    avg_confidence = df['confidence'].mean()\n",
        "    print(f\"\\nüéØ Average confidence: {avg_confidence:.3f}\")\n",
        "\n",
        "    print(f\"\\nüìã RESULTS PREVIEW:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Show most confident predictions\n",
        "    print(f\"\\nüèÜ MOST CONFIDENT PREDICTIONS:\")\n",
        "    print(\"-\" * 40)\n",
        "    top_confident = df.nlargest(3, 'confidence')\n",
        "    for _, row in top_confident.iterrows():\n",
        "        print(f\"Sentiment: {row['sentiment']} (confidence: {row['confidence']})\")\n",
        "        print(f\"Tweet: {row['tweet'][:100]}...\")\n",
        "        print()\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No tweets to analyze\")\n",
        "\n",
        "print(f\"\\n‚úÖ Pipeline completed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "da-Ze7og_vHp",
        "outputId": "df592dd2-1219-453c-bfbc-aec5dde2ee57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160 confirmed attendees, 500+ registrations. I'm excited to launch our AI community in CDMX. Grateful to cursor_ai an stripe for sponsoring our event and to fintual for partnering. See you Thursday!\n"
          ]
        }
      ],
      "source": [
        "print(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glM2xUGFaTMh"
      },
      "source": [
        "### Obtain last tweets associated to specific theme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uuhkIP8Z-x3b",
        "outputId": "26c6ad0b-7ae6-46d8-f901-e2caa3ab505a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tweepy.client:Rate limit exceeded. Sleeping for 784 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ü•§ COCA-COLA SENTIMENT ANALYSIS PIPELINE\n",
            "============================================================\n",
            "üîç Initial memory usage: 2074.42 MB\n",
            "üïê Started at: 15:19:50\n",
            "\n",
            "üîß SETTING UP TWITTER API\n",
            "------------------------------\n",
            "üîë Bearer token configured: AAAAAAAAAAAAAAAAAAAA...\n",
            "‚úÖ API client initialized in 0.00s\n",
            "\n",
            "üîç FETCHING COCA-COLA TWEETS\n",
            "------------------------------\n",
            "üéØ Query: (\"Coca-cola\" OR \"#cocacola\") lang:en -is:retweet\n",
            "üìä Max results: 10\n",
            "üåê Language: English only\n",
            "üö´ Excluding retweets\n",
            "üöÄ Starting tweet search at 15:19:50\n",
            "‚úÖ Search completed in 784.22s\n",
            "üì• Retrieved 10 tweets\n",
            "üìù Tweet length stats:\n",
            "   Average: 239.8 characters\n",
            "   Range: 72-301 characters\n",
            "\n",
            "üßπ TWEET CLEANING\n",
            "------------------------------\n",
            "üîÑ Processing 10 tweets...\n",
            "   Tweet 1: 260‚Üí260 chars (URLs:0, @:0, #:0)\n",
            "   Tweet 2: 200‚Üí190 chars (URLs:0, @:1, #:0)\n",
            "   Tweet 3: 245‚Üí245 chars (URLs:0, @:0, #:0)\n",
            "   Tweet 4: 290‚Üí266 chars (URLs:1, @:0, #:0)\n",
            "   Tweet 5: 72‚Üí55 chars (URLs:0, @:1, #:0)\n",
            "   Tweet 6: 301‚Üí265 chars (URLs:1, @:1, #:0)\n",
            "   Tweet 7: 254‚Üí240 chars (URLs:0, @:1, #:0)\n",
            "   Tweet 8: 249‚Üí240 chars (URLs:0, @:1, #:0)\n",
            "   Tweet 9: 253‚Üí240 chars (URLs:0, @:1, #:0)\n",
            "   Tweet 10: 274‚Üí249 chars (URLs:0, @:2, #:0)\n",
            "\n",
            "‚úÖ Cleaning completed in 0.001s\n",
            "üìä Cleaning summary:\n",
            "   Total character reduction: 148\n",
            "   Average reduction per tweet: 14.8\n",
            "   Elements removed: 2 URLs, 8 mentions, 0 hashtags\n",
            "\n",
            "ü§ñ LOADING SENTIMENT MODEL\n",
            "------------------------------\n",
            "üì¶ Model: cardiffnlp/twitter-roberta-base-sentiment\n",
            "üîÑ Loading tokenizer...\n",
            "üîÑ Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model components loaded:\n",
            "   Tokenizer: 0.27s\n",
            "   Model: 0.33s\n",
            "   Total: 0.60s\n",
            "üíæ Model memory usage: +3.13 MB\n",
            "üè∑Ô∏è  Sentiment labels: ['Negative', 'Neutral', 'Positive']\n",
            "\n",
            "üé≠ SENTIMENT ANALYSIS\n",
            "------------------------------\n",
            "üöÄ Starting sentiment analysis of 10 tweets...\n",
            "  üîÑ Processing tweet 1/10... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative (0.807) - 0.282s\n",
            "  üîÑ Processing tweet 2/10... Neutral (0.537) - 0.182s\n",
            "  üîÑ Processing tweet 3/10... Positive (0.911) - 0.285s\n",
            "  üîÑ Processing tweet 4/10... Negative (0.464) - 0.232s\n",
            "  üîÑ Processing tweet 5/10... Neutral (0.512) - 0.089s\n",
            "  üîÑ Processing tweet 6/10... Positive (0.972) - 0.257s\n",
            "  üîÑ Processing tweet 7/10... Negative (0.713) - 0.242s\n",
            "  üîÑ Processing tweet 8/10... Negative (0.713) - 0.230s\n",
            "  üîÑ Processing tweet 9/10... Negative (0.713) - 0.225s\n",
            "  üîÑ Processing tweet 10/10... Negative (0.684) - 0.219s\n",
            "\n",
            "üéâ ANALYSIS COMPLETE!\n",
            "==================================================\n",
            "‚è±Ô∏è  Total pipeline time: 787.07s\n",
            "üé≠ Analysis phase time: 2.24s\n",
            "üíæ Final memory usage: 1881.23 MB (+-193.19 MB)\n",
            "\n",
            "‚ö° PERFORMANCE BREAKDOWN:\n",
            "   Average per tweet: 0.224s\n",
            "   Tokenization: 0.001s (0.4%)\n",
            "   Inference: 0.223s (99.6%)\n",
            "   Post-processing: 0.000s (0.1%)\n",
            "\n",
            "ü•§ COCA-COLA SENTIMENT DISTRIBUTION:\n",
            "----------------------------------------\n",
            "   üòû Negative: 6 tweets (60.0%)\n",
            "   üòê Neutral: 2 tweets (20.0%)\n",
            "   üòä Positive: 2 tweets (20.0%)\n",
            "\n",
            "üéØ CONFIDENCE METRICS:\n",
            "   Average confidence: 0.703\n",
            "   High confidence (‚â•0.8): 3/10 tweets\n",
            "\n",
            "üìã RESULTS PREVIEW:\n",
            "--------------------------------------------------\n",
            "                                               tweet sentiment  confidence  \\\n",
            "0  armies who want to become OT6 and are eagerly ...  Negative       0.807   \n",
            "1  when you reintroduce the sugar cane product, p...   Neutral       0.537   \n",
            "2  i mean bts used to be using their voice A LOT,...  Positive       0.911   \n",
            "3  She isn't their ambassador, she didn't PROMOTE...  Negative       0.464   \n",
            "4  Coca-Cola has clarified that they do not suppo...   Neutral       0.512   \n",
            "5  Stopping at Skyline is always a win, but now y...  Positive       0.972   \n",
            "6  Fans need a reality check to prioritize what‚Äôs...  Negative       0.713   \n",
            "7  Fans need a reality check to prioritize what‚Äôs...  Negative       0.713   \n",
            "8  Fans need a reality check to prioritize what‚Äôs...  Negative       0.713   \n",
            "9  I think you know he is promoting coca cola whi...  Negative       0.684   \n",
            "\n",
            "  Platform  \n",
            "0        X  \n",
            "1        X  \n",
            "2        X  \n",
            "3        X  \n",
            "4        X  \n",
            "5        X  \n",
            "6        X  \n",
            "7        X  \n",
            "8        X  \n",
            "9        X  \n",
            "\n",
            "üèÜ MOST CONFIDENT PREDICTIONS:\n",
            "----------------------------------------\n",
            "üòä Positive (confidence: 0.972):\n",
            "   \"Stopping at Skyline is always a win, but now you have a chance to win even more ...\"\n",
            "\n",
            "üòû Negative (confidence: 0.807):\n",
            "   \"armies who want to become OT6 and are eagerly awaiting the group's return, burni...\"\n",
            "\n",
            "üòê Neutral (confidence: 0.537):\n",
            "   \"when you reintroduce the sugar cane product, please do the same for Dr. Pepper, ...\"\n",
            "\n",
            "‚úÖ Coca-Cola sentiment analysis pipeline completed!\n",
            "üïê Finished at: 15:32:57\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "import time\n",
        "import psutil\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ü•§ COCA-COLA SENTIMENT ANALYSIS PIPELINE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Monitor system resources\n",
        "process = psutil.Process()\n",
        "memory_start = process.memory_info().rss / 1024**2\n",
        "print(f\"üîç Initial memory usage: {memory_start:.2f} MB\")\n",
        "print(f\"üïê Started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "overall_start = time.time()\n",
        "\n",
        "# ------------------------------\n",
        "# 1. SETUP: Twitter API\n",
        "# ------------------------------\n",
        "print(f\"\\nüîß SETTING UP TWITTER API\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "bearer_token = BEARER_TOKEN\n",
        "print(f\"üîë Bearer token configured: {bearer_token[:20]}...\")\n",
        "\n",
        "api_start = time.time()\n",
        "client = tweepy.Client(bearer_token=bearer_token, wait_on_rate_limit=True)\n",
        "api_duration = time.time() - api_start\n",
        "print(f\"‚úÖ API client initialized in {api_duration:.2f}s\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2. QUERY & FETCH TWEETS\n",
        "# ------------------------------\n",
        "print(f\"\\nüîç FETCHING COCA-COLA TWEETS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "query = '(\"Coca-cola\" OR \"#cocacola\") lang:en -is:retweet'\n",
        "max_results = 10\n",
        "\n",
        "print(f\"üéØ Query: {query}\")\n",
        "print(f\"üìä Max results: {max_results}\")\n",
        "print(f\"üåê Language: English only\")\n",
        "print(f\"üö´ Excluding retweets\")\n",
        "\n",
        "fetch_start = time.time()\n",
        "\n",
        "try:\n",
        "    print(f\"üöÄ Starting tweet search at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    response = client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=['text'])\n",
        "    fetch_duration = time.time() - fetch_start\n",
        "\n",
        "    tweets = [tweet.text for tweet in response.data] if response.data else []\n",
        "\n",
        "    print(f\"‚úÖ Search completed in {fetch_duration:.2f}s\")\n",
        "    print(f\"üì• Retrieved {len(tweets)} tweets\")\n",
        "\n",
        "    if tweets:\n",
        "        avg_length = sum(len(tweet) for tweet in tweets) / len(tweets)\n",
        "        max_length = max(len(tweet) for tweet in tweets)\n",
        "        min_length = min(len(tweet) for tweet in tweets)\n",
        "        print(f\"üìù Tweet length stats:\")\n",
        "        print(f\"   Average: {avg_length:.1f} characters\")\n",
        "        print(f\"   Range: {min_length}-{max_length} characters\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No tweets found for this query\")\n",
        "\n",
        "except tweepy.errors.TooManyRequests as e:\n",
        "    fetch_duration = time.time() - fetch_start\n",
        "    print(f\"‚è≥ Rate limit hit after {fetch_duration:.2f}s: {e}\")\n",
        "    print(\"üîÑ Waiting 60s before retry...\")\n",
        "\n",
        "    wait_start = time.time()\n",
        "    time.sleep(60)\n",
        "    wait_duration = time.time() - wait_start\n",
        "\n",
        "    print(f\"‚è∞ Waited {wait_duration:.1f}s, retrying...\")\n",
        "    retry_start = time.time()\n",
        "    response = client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=['text'])\n",
        "    retry_duration = time.time() - retry_start\n",
        "\n",
        "    tweets = [tweet.text for tweet in response.data] if response.data else []\n",
        "    print(f\"‚úÖ Retry successful in {retry_duration:.2f}s\")\n",
        "    print(f\"üì• Retrieved {len(tweets)} tweets\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3. CLEANING FUNCTION\n",
        "# ------------------------------\n",
        "print(f\"\\nüßπ TWEET CLEANING\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    original_length = len(tweet)\n",
        "\n",
        "    # Count elements being removed\n",
        "    urls = len(re.findall(r\"http\\S+\", tweet))\n",
        "    mentions = len(re.findall(r\"@\\w+\", tweet))\n",
        "    hashtags = len(re.findall(r\"#\\w+\", tweet))\n",
        "\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)  # remove URLs\n",
        "    tweet = re.sub(r\"@\\w+\", \"\", tweet)     # remove mentions\n",
        "    tweet = re.sub(r\"#\", \"\", tweet)        # remove hashtag symbol\n",
        "    tweet = re.sub(r\"\\s+\", \" \", tweet).strip()\n",
        "\n",
        "    cleaned_length = len(tweet)\n",
        "\n",
        "    return tweet, {\n",
        "        'original_length': original_length,\n",
        "        'cleaned_length': cleaned_length,\n",
        "        'urls_removed': urls,\n",
        "        'mentions_removed': mentions,\n",
        "        'hashtags_removed': hashtags,\n",
        "        'reduction': original_length - cleaned_length\n",
        "    }\n",
        "\n",
        "# Clean all tweets and track statistics\n",
        "cleaning_start = time.time()\n",
        "cleaning_stats = []\n",
        "cleaned_tweets = []\n",
        "\n",
        "print(f\"üîÑ Processing {len(tweets)} tweets...\")\n",
        "\n",
        "for i, tweet in enumerate(tweets, 1):\n",
        "    clean_text, stats = clean_tweet(tweet)\n",
        "    cleaned_tweets.append(clean_text)\n",
        "    cleaning_stats.append(stats)\n",
        "\n",
        "    print(f\"   Tweet {i}: {stats['original_length']}‚Üí{stats['cleaned_length']} chars \"\n",
        "          f\"(URLs:{stats['urls_removed']}, @:{stats['mentions_removed']}, #:{stats['hashtags_removed']})\")\n",
        "\n",
        "cleaning_duration = time.time() - cleaning_start\n",
        "\n",
        "if cleaning_stats:\n",
        "    total_reduction = sum(stat['reduction'] for stat in cleaning_stats)\n",
        "    avg_reduction = total_reduction / len(cleaning_stats)\n",
        "    total_urls = sum(stat['urls_removed'] for stat in cleaning_stats)\n",
        "    total_mentions = sum(stat['mentions_removed'] for stat in cleaning_stats)\n",
        "    total_hashtags = sum(stat['hashtags_removed'] for stat in cleaning_stats)\n",
        "\n",
        "    print(f\"\\n‚úÖ Cleaning completed in {cleaning_duration:.3f}s\")\n",
        "    print(f\"üìä Cleaning summary:\")\n",
        "    print(f\"   Total character reduction: {total_reduction}\")\n",
        "    print(f\"   Average reduction per tweet: {avg_reduction:.1f}\")\n",
        "    print(f\"   Elements removed: {total_urls} URLs, {total_mentions} mentions, {total_hashtags} hashtags\")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. LOAD SENTIMENT MODEL\n",
        "# ------------------------------\n",
        "print(f\"\\nü§ñ LOADING SENTIMENT MODEL\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "print(f\"üì¶ Model: {MODEL}\")\n",
        "\n",
        "model_start = time.time()\n",
        "\n",
        "print(\"üîÑ Loading tokenizer...\")\n",
        "tokenizer_start = time.time()\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "tokenizer_duration = time.time() - tokenizer_start\n",
        "\n",
        "print(\"üîÑ Loading model...\")\n",
        "model_load_start = time.time()\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model_load_duration = time.time() - model_load_start\n",
        "\n",
        "model_duration = time.time() - model_start\n",
        "memory_after_model = process.memory_info().rss / 1024**2\n",
        "model_memory = memory_after_model - memory_start\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "print(f\"‚úÖ Model components loaded:\")\n",
        "print(f\"   Tokenizer: {tokenizer_duration:.2f}s\")\n",
        "print(f\"   Model: {model_load_duration:.2f}s\")\n",
        "print(f\"   Total: {model_duration:.2f}s\")\n",
        "print(f\"üíæ Model memory usage: +{model_memory:.2f} MB\")\n",
        "print(f\"üè∑Ô∏è  Sentiment labels: {labels}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. PREDICT SENTIMENTS\n",
        "# ------------------------------\n",
        "print(f\"\\nüé≠ SENTIMENT ANALYSIS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "def get_sentiment(text):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Tokenization timing\n",
        "    tokenize_start = time.time()\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True)\n",
        "    tokenize_duration = time.time() - tokenize_start\n",
        "\n",
        "    # Model inference timing\n",
        "    inference_start = time.time()\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    inference_duration = time.time() - inference_start\n",
        "\n",
        "    # Post-processing timing\n",
        "    postprocess_start = time.time()\n",
        "    scores = output.logits[0].numpy()\n",
        "    scores = softmax(scores)\n",
        "    sentiment = labels[scores.argmax()]\n",
        "    confidence = scores.max()\n",
        "    postprocess_duration = time.time() - postprocess_start\n",
        "\n",
        "    total_duration = time.time() - start_time\n",
        "\n",
        "    return sentiment, float(confidence), {\n",
        "        'total_time': total_duration,\n",
        "        'tokenize_time': tokenize_duration,\n",
        "        'inference_time': inference_duration,\n",
        "        'postprocess_time': postprocess_duration\n",
        "    }\n",
        "\n",
        "# ------------------------------\n",
        "# 6. ANALYZE AND OUTPUT RESULTS\n",
        "# ------------------------------\n",
        "print(f\"üöÄ Starting sentiment analysis of {len(cleaned_tweets)} tweets...\")\n",
        "\n",
        "analysis_start = time.time()\n",
        "results = []\n",
        "timing_stats = []\n",
        "\n",
        "for i, tweet in enumerate(cleaned_tweets, 1):\n",
        "    print(f\"  üîÑ Processing tweet {i}/{len(cleaned_tweets)}...\", end=\" \")\n",
        "\n",
        "    sentiment, confidence, timing = get_sentiment(tweet)\n",
        "    timing_stats.append(timing)\n",
        "\n",
        "    results.append({\n",
        "        'tweet': tweet,\n",
        "        'sentiment': sentiment,\n",
        "        'confidence': round(confidence, 3),\n",
        "        'Platform': 'X'\n",
        "    })\n",
        "\n",
        "    print(f\"{sentiment} ({confidence:.3f}) - {timing['total_time']:.3f}s\")\n",
        "\n",
        "analysis_duration = time.time() - analysis_start\n",
        "overall_duration = time.time() - overall_start\n",
        "memory_final = process.memory_info().rss / 1024**2\n",
        "\n",
        "# Create DataFrame\n",
        "df_tweets_sentiment = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\nüéâ ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚è±Ô∏è  Total pipeline time: {overall_duration:.2f}s\")\n",
        "print(f\"üé≠ Analysis phase time: {analysis_duration:.2f}s\")\n",
        "print(f\"üíæ Final memory usage: {memory_final:.2f} MB (+{memory_final - memory_start:.2f} MB)\")\n",
        "\n",
        "# Timing breakdown\n",
        "if timing_stats:\n",
        "    avg_total = sum(t['total_time'] for t in timing_stats) / len(timing_stats)\n",
        "    avg_tokenize = sum(t['tokenize_time'] for t in timing_stats) / len(timing_stats)\n",
        "    avg_inference = sum(t['inference_time'] for t in timing_stats) / len(timing_stats)\n",
        "    avg_postprocess = sum(t['postprocess_time'] for t in timing_stats) / len(timing_stats)\n",
        "\n",
        "    print(f\"\\n‚ö° PERFORMANCE BREAKDOWN:\")\n",
        "    print(f\"   Average per tweet: {avg_total:.3f}s\")\n",
        "    print(f\"   Tokenization: {avg_tokenize:.3f}s ({avg_tokenize/avg_total*100:.1f}%)\")\n",
        "    print(f\"   Inference: {avg_inference:.3f}s ({avg_inference/avg_total*100:.1f}%)\")\n",
        "    print(f\"   Post-processing: {avg_postprocess:.3f}s ({avg_postprocess/avg_total*100:.1f}%)\")\n",
        "\n",
        "# Sentiment analysis results\n",
        "if not df_tweets_sentiment.empty:\n",
        "    sentiment_counts = df_tweets_sentiment['sentiment'].value_counts()\n",
        "    print(f\"\\nü•§ COCA-COLA SENTIMENT DISTRIBUTION:\")\n",
        "    print(\"-\" * 40)\n",
        "    for sentiment, count in sentiment_counts.items():\n",
        "        percentage = (count / len(df_tweets_sentiment)) * 100\n",
        "        emoji = \"üòä\" if sentiment == \"Positive\" else \"üòê\" if sentiment == \"Neutral\" else \"üòû\"\n",
        "        print(f\"   {emoji} {sentiment}: {count} tweets ({percentage:.1f}%)\")\n",
        "\n",
        "    avg_confidence = df_tweets_sentiment['confidence'].mean()\n",
        "    high_confidence = (df_tweets_sentiment['confidence'] >= 0.8).sum()\n",
        "\n",
        "    print(f\"\\nüéØ CONFIDENCE METRICS:\")\n",
        "    print(f\"   Average confidence: {avg_confidence:.3f}\")\n",
        "    print(f\"   High confidence (‚â•0.8): {high_confidence}/{len(df_tweets_sentiment)} tweets\")\n",
        "\n",
        "    print(f\"\\nüìã RESULTS PREVIEW:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(df_tweets_sentiment.head(10))\n",
        "\n",
        "    # Show most confident predictions by sentiment\n",
        "    print(f\"\\nüèÜ MOST CONFIDENT PREDICTIONS:\")\n",
        "    print(\"-\" * 40)\n",
        "    for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
        "        sentiment_tweets = df_tweets_sentiment[df_tweets_sentiment['sentiment'] == sentiment]\n",
        "        if not sentiment_tweets.empty:\n",
        "            top_tweet = sentiment_tweets.loc[sentiment_tweets['confidence'].idxmax()]\n",
        "            emoji = \"üòä\" if sentiment == \"Positive\" else \"üòê\" if sentiment == \"Neutral\" else \"üòû\"\n",
        "            print(f\"{emoji} {sentiment} (confidence: {top_tweet['confidence']}):\")\n",
        "            print(f\"   \\\"{top_tweet['tweet'][:80]}...\\\"\")\n",
        "            print()\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No tweets to analyze\")\n",
        "\n",
        "print(f\"‚úÖ Coca-Cola sentiment analysis pipeline completed!\")\n",
        "print(f\"üïê Finished at: {datetime.now().strftime('%H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3uHoNeZW3_j"
      },
      "source": [
        "### Upload Sentiment DDBB too Big Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "90n8BbptW3zS",
        "outputId": "fc057804-acd8-4275-defb-172a6a1ca69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ BIGQUERY UPLOAD - SENTIMENT DATA\n",
            "========================================\n",
            "üìä Dataset info:\n",
            "   Rows: 10\n",
            "   Columns: 4\n",
            "   Size: 7.6 KB\n",
            "   Target: proof-of-brand.social_media_metrics.tweets_sentiment_data\n",
            "   Sentiment breakdown: {'Negative': np.int64(6), 'Neutral': np.int64(2), 'Positive': np.int64(2)}\n",
            "\n",
            "üöÄ Starting upload at 15:32:57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas_gbq/gbq.py:528: FutureWarning: verbose is deprecated and will be removed in a future version. Set logging level in order to vary verbosity\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11214.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ UPLOAD SUCCESSFUL!\n",
            "‚è±Ô∏è  Upload time: 3.61s\n",
            "üìà Upload rate: 2.8 rows/second\n",
            "üéØ Table: proof-of-brand.social_media_metrics.tweets_sentiment_data\n",
            "üîó View in BigQuery: https://console.cloud.google.com/bigquery?project=proof-of-brand\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "project_id = \"proof-of-brand\"\n",
        "dataset_id = \"social_media_metrics\"\n",
        "table_id_tweets_sentiment = \"tweets_sentiment_data\"\n",
        "\n",
        "print(\"üì§ BIGQUERY UPLOAD - SENTIMENT DATA\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Pre-upload analysis\n",
        "print(f\"üìä Dataset info:\")\n",
        "print(f\"   Rows: {len(df_tweets_sentiment)}\")\n",
        "print(f\"   Columns: {df_tweets_sentiment.shape[1]}\")\n",
        "print(f\"   Size: {df_tweets_sentiment.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
        "print(f\"   Target: {project_id}.{dataset_id}.{table_id_tweets_sentiment}\")\n",
        "\n",
        "# Show sentiment distribution being uploaded\n",
        "if not df_tweets_sentiment.empty:\n",
        "    sentiment_counts = df_tweets_sentiment['sentiment'].value_counts()\n",
        "    print(f\"   Sentiment breakdown: {dict(sentiment_counts)}\")\n",
        "\n",
        "print(f\"\\nüöÄ Starting upload at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "upload_start = time.time()\n",
        "\n",
        "try:\n",
        "    to_gbq(\n",
        "        df_tweets_sentiment,\n",
        "        f\"{dataset_id}.{table_id_tweets_sentiment}\",\n",
        "        project_id=project_id,\n",
        "        if_exists='replace',\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    upload_duration = time.time() - upload_start\n",
        "\n",
        "    print(f\"\\n‚úÖ UPLOAD SUCCESSFUL!\")\n",
        "    print(f\"‚è±Ô∏è  Upload time: {upload_duration:.2f}s\")\n",
        "    print(f\"üìà Upload rate: {len(df_tweets_sentiment)/upload_duration:.1f} rows/second\")\n",
        "    print(f\"üéØ Table: {project_id}.{dataset_id}.{table_id_tweets_sentiment}\")\n",
        "\n",
        "except Exception as e:\n",
        "    upload_duration = time.time() - upload_start\n",
        "    print(f\"\\n‚ùå UPLOAD FAILED after {upload_duration:.2f}s\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "print(f\"üîó View in BigQuery: https://console.cloud.google.com/bigquery?project={project_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tWtU9PhX5Ua"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPt3ykuDRrzmS9LIR6UiwdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}